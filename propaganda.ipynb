{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "19qLLp1VEUCZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92c9adba-8d2c-445f-a63f-44ba0df31c85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n",
            "Collecting datasets\n",
            "  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Collecting dill<0.3.7,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.15.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: xxhash, dill, multiprocess, datasets\n",
            "Successfully installed datasets-2.13.1 dill-0.3.6 multiprocess-0.70.14 xxhash-3.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip3 install transformers\n",
        "!pip3 install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "2j7ZRzpTs2XO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "xaNrX0FVEUCb"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "from transformers import pipeline\n",
        "import operator\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import transformers\n",
        "\n",
        "from datasets import load_dataset\n",
        "from tensorflow import keras\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import TFAutoModel\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1Nq9IKDFEUCc"
      },
      "outputs": [],
      "source": [
        "f = open(\"training_task1.txt\", \"r\")\n",
        "lines = f.read()\n",
        "\n",
        "lines = lines.replace(\"}{\", \"},{\")\n",
        "lines = json.loads(lines)\n",
        "\n",
        "# Lines is a list of dictionaries, where each dictionary is a single sentence with its labels.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "MZXYdEyXEUCc"
      },
      "outputs": [],
      "source": [
        "sentences = []\n",
        "labels = []\n",
        "\n",
        "\n",
        "for sentence in lines:\n",
        "    sentences.append(sentence[\"text\"].replace(\"\\n\", \" \"))\n",
        "    labels.append(sentence[\"labels\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_labels = {}\n",
        "\n",
        "for label in labels:\n",
        "  if len(label) == 0:\n",
        "      label.append('none')\n",
        "  for sub_label in label:\n",
        "    if ''.join(sub_label) not in list_of_labels.keys():\n",
        "      str_label = ''.join(sub_label).lower()\n",
        "      str_label = re.sub(r\"[^a-zA-Z0-9]+\", ' ', str_label)\n",
        "      if str_label not in list_of_labels.keys():\n",
        "        list_of_labels[str_label] = len(list_of_labels)\n",
        "\n",
        "print(list_of_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_R4JZcX7zDy",
        "outputId": "f353cb5d-5958-40d0-8618-1a3dee6cd250"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'black and white fallacy dictatorship': 0, 'none': 1, 'loaded language': 2, 'name calling labeling': 3, 'slogans': 4, 'smears': 5, 'causal oversimplification': 6, 'appeal to fear prejudice': 7, 'exaggeration minimisation': 8, 'reductio ad hitlerum': 9, 'repetition': 10, 'glittering generalities virtue ': 11, 'misrepresentation of someone s position straw man ': 12, 'doubt': 13, 'obfuscation intentional vagueness confusion': 14, 'whataboutism': 15, 'flag waving': 16, 'thought terminating clich ': 17, 'presenting irrelevant data red herring ': 18, 'appeal to authority': 19, 'bandwagon': 20}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(labels[2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wllR5OtT_pfo",
        "outputId": "1bbfa354-1f95-4186-a1f6-8f7fae13895b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Loaded Language', 'Name calling/Labeling', 'Slogans', 'Smears']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Rz8w6LqlEUCc"
      },
      "outputs": [],
      "source": [
        "class Dataset:\n",
        "    def __init__(self, sentences, labels):\n",
        "        self.sentences = sentences\n",
        "        self.labels = labels\n",
        "\n",
        "    @staticmethod\n",
        "    def preprocess(sentences, labels):\n",
        "\n",
        "        preprocessed_sentences = []\n",
        "        preprocessed_labels = []\n",
        "        numbered_labels = []\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence = sentence.lower()\n",
        "            sentence = re.sub(r\"[^a-zA-Z0-9]+\", ' ', sentence)\n",
        "            sentence = re.sub(r\"http\\S+\", \"\", sentence)\n",
        "            sentence = re.sub(r\"www\\S+\", \"\", sentence)\n",
        "            preprocessed_sentences.append(sentence)\n",
        "\n",
        "        for i in range(len(labels)):\n",
        "            label = labels[i]\n",
        "            list_of_labels_for_a_sent = []\n",
        "            numbered_labels_for_a_sent = []\n",
        "            for j in range(len(label)):\n",
        "                label[j] = label[j].lower()\n",
        "                label[j] = re.sub(r\"[^a-zA-Z0-9]+\", ' ', label[j])\n",
        "                list_of_labels_for_a_sent.append(label[j].split(\",\"))\n",
        "                temp_label_in_string = ' '.join(label[j].split(\",\"))\n",
        "                numbered_labels_for_a_sent.append([list_of_labels[temp_label_in_string]])\n",
        "\n",
        "\n",
        "\n",
        "            preprocessed_labels.append(list_of_labels_for_a_sent)\n",
        "            numbered_labels.append(numbered_labels_for_a_sent)\n",
        "\n",
        "            print(list_of_labels_for_a_sent)\n",
        "            print(numbered_labels_for_a_sent)\n",
        "\n",
        "        return preprocessed_sentences, numbered_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OqNhJoEEEUCd",
        "outputId": "e1564227-6044-4c2d-ac5b-00bc0ce20b49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['black and white fallacy dictatorship']]\n",
            "[[0]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling'], ['slogans'], ['smears']]\n",
            "[[2], [3], [4], [5]]\n",
            "[['causal oversimplification'], ['loaded language'], ['name calling labeling'], ['slogans'], ['smears']]\n",
            "[[6], [2], [3], [4], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['appeal to fear prejudice'], ['causal oversimplification'], ['exaggeration minimisation'], ['slogans']]\n",
            "[[7], [6], [8], [4]]\n",
            "[['loaded language'], ['name calling labeling'], ['reductio ad hitlerum'], ['smears']]\n",
            "[[2], [3], [9], [5]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['loaded language'], ['name calling labeling'], ['repetition']]\n",
            "[[2], [3], [10]]\n",
            "[['causal oversimplification'], ['glittering generalities virtue '], ['loaded language'], ['name calling labeling']]\n",
            "[[6], [11], [2], [3]]\n",
            "[['appeal to fear prejudice'], ['loaded language'], ['slogans'], ['smears']]\n",
            "[[7], [2], [4], [5]]\n",
            "[['causal oversimplification'], ['loaded language'], ['name calling labeling']]\n",
            "[[6], [2], [3]]\n",
            "[['misrepresentation of someone s position straw man ']]\n",
            "[[12]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language'], ['slogans']]\n",
            "[[2], [4]]\n",
            "[['exaggeration minimisation'], ['glittering generalities virtue '], ['loaded language'], ['misrepresentation of someone s position straw man '], ['name calling labeling'], ['smears']]\n",
            "[[8], [11], [2], [12], [3], [5]]\n",
            "[['appeal to fear prejudice'], ['loaded language'], ['slogans']]\n",
            "[[7], [2], [4]]\n",
            "[['exaggeration minimisation'], ['loaded language'], ['smears']]\n",
            "[[8], [2], [5]]\n",
            "[['doubt'], ['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[13], [2], [3], [5]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['repetition']]\n",
            "[[10]]\n",
            "[['loaded language'], ['misrepresentation of someone s position straw man '], ['name calling labeling'], ['obfuscation intentional vagueness confusion'], ['smears']]\n",
            "[[2], [12], [3], [14], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['slogans']]\n",
            "[[2], [4]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears'], ['whataboutism']]\n",
            "[[2], [3], [5], [15]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['exaggeration minimisation'], ['name calling labeling'], ['smears']]\n",
            "[[8], [3], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['appeal to fear prejudice'], ['causal oversimplification'], ['exaggeration minimisation'], ['loaded language']]\n",
            "[[7], [6], [8], [2]]\n",
            "[['causal oversimplification']]\n",
            "[[6]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['causal oversimplification'], ['glittering generalities virtue '], ['smears']]\n",
            "[[6], [11], [5]]\n",
            "[['appeal to fear prejudice'], ['exaggeration minimisation'], ['flag waving'], ['loaded language'], ['name calling labeling']]\n",
            "[[7], [8], [16], [2], [3]]\n",
            "[['appeal to fear prejudice'], ['black and white fallacy dictatorship'], ['slogans']]\n",
            "[[7], [0], [4]]\n",
            "[['flag waving'], ['slogans'], ['smears']]\n",
            "[[16], [4], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['appeal to fear prejudice'], ['black and white fallacy dictatorship'], ['exaggeration minimisation'], ['name calling labeling'], ['reductio ad hitlerum'], ['slogans'], ['smears'], ['thought terminating clich ']]\n",
            "[[7], [0], [8], [3], [9], [4], [5], [17]]\n",
            "[['loaded language'], ['name calling labeling'], ['whataboutism']]\n",
            "[[2], [3], [15]]\n",
            "[['name calling labeling']]\n",
            "[[3]]\n",
            "[['name calling labeling']]\n",
            "[[3]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['causal oversimplification'], ['smears']]\n",
            "[[6], [5]]\n",
            "[['exaggeration minimisation'], ['flag waving'], ['loaded language'], ['misrepresentation of someone s position straw man '], ['smears']]\n",
            "[[8], [16], [2], [12], [5]]\n",
            "[['flag waving'], ['loaded language'], ['name calling labeling'], ['reductio ad hitlerum'], ['slogans'], ['smears']]\n",
            "[[16], [2], [3], [9], [4], [5]]\n",
            "[['glittering generalities virtue '], ['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[11], [2], [3], [5]]\n",
            "[['loaded language'], ['slogans']]\n",
            "[[2], [4]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['loaded language'], ['name calling labeling'], ['reductio ad hitlerum'], ['smears']]\n",
            "[[2], [3], [9], [5]]\n",
            "[['exaggeration minimisation'], ['smears']]\n",
            "[[8], [5]]\n",
            "[['reductio ad hitlerum']]\n",
            "[[9]]\n",
            "[['presenting irrelevant data red herring ']]\n",
            "[[18]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['appeal to fear prejudice'], ['causal oversimplification'], ['glittering generalities virtue '], ['loaded language']]\n",
            "[[7], [6], [11], [2]]\n",
            "[['slogans'], ['smears']]\n",
            "[[4], [5]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['appeal to authority'], ['black and white fallacy dictatorship'], ['loaded language'], ['name calling labeling']]\n",
            "[[19], [0], [2], [3]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['causal oversimplification'], ['smears'], ['thought terminating clich ']]\n",
            "[[6], [5], [17]]\n",
            "[['loaded language'], ['misrepresentation of someone s position straw man '], ['obfuscation intentional vagueness confusion']]\n",
            "[[2], [12], [14]]\n",
            "[['name calling labeling']]\n",
            "[[3]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['exaggeration minimisation'], ['loaded language']]\n",
            "[[8], [2]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['exaggeration minimisation']]\n",
            "[[8]]\n",
            "[['appeal to authority'], ['exaggeration minimisation'], ['smears']]\n",
            "[[19], [8], [5]]\n",
            "[['name calling labeling'], ['smears'], ['thought terminating clich ']]\n",
            "[[3], [5], [17]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['appeal to fear prejudice'], ['flag waving'], ['loaded language'], ['name calling labeling'], ['smears'], ['whataboutism']]\n",
            "[[7], [16], [2], [3], [5], [15]]\n",
            "[['exaggeration minimisation']]\n",
            "[[8]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['thought terminating clich ']]\n",
            "[[17]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['flag waving'], ['loaded language'], ['name calling labeling']]\n",
            "[[16], [2], [3]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['black and white fallacy dictatorship'], ['doubt']]\n",
            "[[0], [13]]\n",
            "[['exaggeration minimisation'], ['loaded language'], ['misrepresentation of someone s position straw man '], ['slogans'], ['smears']]\n",
            "[[8], [2], [12], [4], [5]]\n",
            "[['doubt'], ['loaded language']]\n",
            "[[13], [2]]\n",
            "[['exaggeration minimisation'], ['smears']]\n",
            "[[8], [5]]\n",
            "[['appeal to fear prejudice'], ['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[7], [2], [3], [5]]\n",
            "[['loaded language'], ['repetition'], ['slogans']]\n",
            "[[2], [10], [4]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['appeal to authority'], ['causal oversimplification'], ['loaded language'], ['name calling labeling'], ['thought terminating clich ']]\n",
            "[[19], [6], [2], [3], [17]]\n",
            "[['doubt'], ['exaggeration minimisation'], ['name calling labeling']]\n",
            "[[13], [8], [3]]\n",
            "[['loaded language'], ['slogans']]\n",
            "[[2], [4]]\n",
            "[['appeal to fear prejudice'], ['flag waving']]\n",
            "[[7], [16]]\n",
            "[['name calling labeling']]\n",
            "[[3]]\n",
            "[['flag waving'], ['loaded language'], ['name calling labeling'], ['slogans']]\n",
            "[[16], [2], [3], [4]]\n",
            "[['appeal to fear prejudice'], ['loaded language'], ['name calling labeling']]\n",
            "[[7], [2], [3]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['appeal to fear prejudice'], ['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[7], [2], [3], [5]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['black and white fallacy dictatorship']]\n",
            "[[0]]\n",
            "[['appeal to fear prejudice'], ['flag waving'], ['glittering generalities virtue '], ['loaded language'], ['name calling labeling']]\n",
            "[[7], [16], [11], [2], [3]]\n",
            "[['causal oversimplification'], ['exaggeration minimisation'], ['smears'], ['thought terminating clich ']]\n",
            "[[6], [8], [5], [17]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['slogans'], ['smears']]\n",
            "[[4], [5]]\n",
            "[['bandwagon'], ['exaggeration minimisation'], ['loaded language']]\n",
            "[[20], [8], [2]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['appeal to fear prejudice'], ['loaded language']]\n",
            "[[7], [2]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears'], ['whataboutism']]\n",
            "[[2], [3], [5], [15]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['name calling labeling']]\n",
            "[[3]]\n",
            "[['appeal to fear prejudice'], ['thought terminating clich ']]\n",
            "[[7], [17]]\n",
            "[['flag waving'], ['loaded language'], ['slogans'], ['smears']]\n",
            "[[16], [2], [4], [5]]\n",
            "[['causal oversimplification'], ['loaded language'], ['smears']]\n",
            "[[6], [2], [5]]\n",
            "[['black and white fallacy dictatorship']]\n",
            "[[0]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['name calling labeling']]\n",
            "[[3]]\n",
            "[['appeal to fear prejudice'], ['loaded language']]\n",
            "[[7], [2]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['exaggeration minimisation'], ['loaded language'], ['misrepresentation of someone s position straw man ']]\n",
            "[[8], [2], [12]]\n",
            "[['name calling labeling']]\n",
            "[[3]]\n",
            "[['appeal to fear prejudice'], ['black and white fallacy dictatorship'], ['loaded language'], ['name calling labeling']]\n",
            "[[7], [0], [2], [3]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['exaggeration minimisation'], ['loaded language'], ['whataboutism']]\n",
            "[[8], [2], [15]]\n",
            "[['exaggeration minimisation']]\n",
            "[[8]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['exaggeration minimisation'], ['smears'], ['thought terminating clich ']]\n",
            "[[8], [5], [17]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['exaggeration minimisation'], ['loaded language'], ['smears']]\n",
            "[[8], [2], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['appeal to fear prejudice'], ['loaded language'], ['smears']]\n",
            "[[7], [2], [5]]\n",
            "[['whataboutism']]\n",
            "[[15]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['doubt'], ['loaded language']]\n",
            "[[13], [2]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['smears'], ['thought terminating clich ']]\n",
            "[[5], [17]]\n",
            "[['causal oversimplification'], ['loaded language']]\n",
            "[[6], [2]]\n",
            "[['loaded language'], ['misrepresentation of someone s position straw man '], ['name calling labeling'], ['slogans']]\n",
            "[[2], [12], [3], [4]]\n",
            "[['flag waving'], ['slogans']]\n",
            "[[16], [4]]\n",
            "[['appeal to fear prejudice'], ['black and white fallacy dictatorship'], ['loaded language'], ['name calling labeling']]\n",
            "[[7], [0], [2], [3]]\n",
            "[['loaded language'], ['name calling labeling'], ['whataboutism']]\n",
            "[[2], [3], [15]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['flag waving'], ['glittering generalities virtue '], ['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[16], [11], [2], [3], [5]]\n",
            "[['black and white fallacy dictatorship'], ['exaggeration minimisation']]\n",
            "[[0], [8]]\n",
            "[['exaggeration minimisation'], ['loaded language'], ['name calling labeling'], ['slogans'], ['smears']]\n",
            "[[8], [2], [3], [4], [5]]\n",
            "[['glittering generalities virtue ']]\n",
            "[[11]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['loaded language'], ['name calling labeling'], ['whataboutism']]\n",
            "[[2], [3], [15]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['slogans'], ['smears']]\n",
            "[[4], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['doubt']]\n",
            "[[13]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['exaggeration minimisation'], ['loaded language']]\n",
            "[[8], [2]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['appeal to fear prejudice'], ['smears']]\n",
            "[[7], [5]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['exaggeration minimisation'], ['name calling labeling']]\n",
            "[[8], [3]]\n",
            "[['causal oversimplification'], ['glittering generalities virtue '], ['smears']]\n",
            "[[6], [11], [5]]\n",
            "[['appeal to fear prejudice'], ['causal oversimplification'], ['misrepresentation of someone s position straw man ']]\n",
            "[[7], [6], [12]]\n",
            "[['black and white fallacy dictatorship'], ['exaggeration minimisation']]\n",
            "[[0], [8]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['doubt']]\n",
            "[[13]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['name calling labeling']]\n",
            "[[3]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['doubt']]\n",
            "[[13]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['name calling labeling'], ['smears']]\n",
            "[[3], [5]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['appeal to fear prejudice'], ['loaded language'], ['name calling labeling'], ['slogans']]\n",
            "[[7], [2], [3], [4]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['exaggeration minimisation'], ['glittering generalities virtue '], ['name calling labeling']]\n",
            "[[8], [11], [3]]\n",
            "[['appeal to authority'], ['loaded language'], ['name calling labeling']]\n",
            "[[19], [2], [3]]\n",
            "[['loaded language'], ['misrepresentation of someone s position straw man '], ['name calling labeling']]\n",
            "[[2], [12], [3]]\n",
            "[['appeal to fear prejudice'], ['loaded language']]\n",
            "[[7], [2]]\n",
            "[['doubt'], ['smears']]\n",
            "[[13], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['doubt']]\n",
            "[[13]]\n",
            "[['causal oversimplification'], ['loaded language'], ['smears']]\n",
            "[[6], [2], [5]]\n",
            "[['flag waving']]\n",
            "[[16]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['exaggeration minimisation'], ['glittering generalities virtue '], ['loaded language'], ['thought terminating clich ']]\n",
            "[[8], [11], [2], [17]]\n",
            "[['exaggeration minimisation'], ['loaded language']]\n",
            "[[8], [2]]\n",
            "[['loaded language'], ['misrepresentation of someone s position straw man '], ['smears']]\n",
            "[[2], [12], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['name calling labeling']]\n",
            "[[3]]\n",
            "[['glittering generalities virtue '], ['loaded language']]\n",
            "[[11], [2]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['doubt']]\n",
            "[[13]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['exaggeration minimisation'], ['glittering generalities virtue '], ['name calling labeling']]\n",
            "[[8], [11], [3]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['exaggeration minimisation']]\n",
            "[[8]]\n",
            "[['name calling labeling']]\n",
            "[[3]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['doubt']]\n",
            "[[13]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['glittering generalities virtue '], ['smears']]\n",
            "[[11], [5]]\n",
            "[['slogans']]\n",
            "[[4]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['doubt']]\n",
            "[[13]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['exaggeration minimisation'], ['name calling labeling']]\n",
            "[[8], [3]]\n",
            "[['doubt']]\n",
            "[[13]]\n",
            "[['name calling labeling']]\n",
            "[[3]]\n",
            "[['whataboutism']]\n",
            "[[15]]\n",
            "[['flag waving'], ['glittering generalities virtue ']]\n",
            "[[16], [11]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['whataboutism']]\n",
            "[[15]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['doubt'], ['whataboutism']]\n",
            "[[13], [15]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['doubt']]\n",
            "[[13]]\n",
            "[['appeal to authority'], ['flag waving'], ['name calling labeling']]\n",
            "[[19], [16], [3]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['exaggeration minimisation'], ['glittering generalities virtue '], ['loaded language']]\n",
            "[[8], [11], [2]]\n",
            "[['glittering generalities virtue '], ['name calling labeling']]\n",
            "[[11], [3]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['glittering generalities virtue '], ['name calling labeling']]\n",
            "[[11], [3]]\n",
            "[['flag waving'], ['slogans']]\n",
            "[[16], [4]]\n",
            "[['exaggeration minimisation']]\n",
            "[[8]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['appeal to authority'], ['slogans']]\n",
            "[[19], [4]]\n",
            "[['exaggeration minimisation'], ['glittering generalities virtue '], ['name calling labeling'], ['smears']]\n",
            "[[8], [11], [3], [5]]\n",
            "[['slogans'], ['smears']]\n",
            "[[4], [5]]\n",
            "[['exaggeration minimisation'], ['loaded language']]\n",
            "[[8], [2]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['causal oversimplification'], ['name calling labeling'], ['smears']]\n",
            "[[6], [3], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['glittering generalities virtue ']]\n",
            "[[11]]\n",
            "[['glittering generalities virtue '], ['smears']]\n",
            "[[11], [5]]\n",
            "[['doubt'], ['whataboutism']]\n",
            "[[13], [15]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['appeal to authority'], ['appeal to fear prejudice'], ['loaded language'], ['name calling labeling']]\n",
            "[[19], [7], [2], [3]]\n",
            "[['name calling labeling'], ['smears']]\n",
            "[[3], [5]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language'], ['name calling labeling'], ['whataboutism']]\n",
            "[[2], [3], [15]]\n",
            "[['appeal to fear prejudice']]\n",
            "[[7]]\n",
            "[['name calling labeling']]\n",
            "[[3]]\n",
            "[['causal oversimplification'], ['loaded language']]\n",
            "[[6], [2]]\n",
            "[['glittering generalities virtue '], ['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[11], [2], [3], [5]]\n",
            "[['black and white fallacy dictatorship']]\n",
            "[[0]]\n",
            "[['appeal to fear prejudice'], ['doubt'], ['loaded language'], ['name calling labeling']]\n",
            "[[7], [13], [2], [3]]\n",
            "[['glittering generalities virtue '], ['smears']]\n",
            "[[11], [5]]\n",
            "[['repetition']]\n",
            "[[10]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears'], ['whataboutism']]\n",
            "[[2], [3], [5], [15]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['flag waving'], ['smears']]\n",
            "[[16], [5]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['smears'], ['whataboutism']]\n",
            "[[5], [15]]\n",
            "[['black and white fallacy dictatorship'], ['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[0], [2], [3], [5]]\n",
            "[['doubt']]\n",
            "[[13]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears'], ['whataboutism']]\n",
            "[[2], [3], [5], [15]]\n",
            "[['causal oversimplification'], ['doubt'], ['loaded language'], ['misrepresentation of someone s position straw man '], ['smears']]\n",
            "[[6], [13], [2], [12], [5]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['doubt'], ['loaded language']]\n",
            "[[13], [2]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language'], ['whataboutism']]\n",
            "[[2], [15]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['appeal to fear prejudice'], ['exaggeration minimisation'], ['loaded language'], ['name calling labeling']]\n",
            "[[7], [8], [2], [3]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['misrepresentation of someone s position straw man '], ['whataboutism']]\n",
            "[[2], [12], [15]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['appeal to fear prejudice'], ['flag waving'], ['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[7], [16], [2], [3], [5]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language'], ['thought terminating clich ']]\n",
            "[[2], [17]]\n",
            "[['loaded language'], ['smears'], ['thought terminating clich ']]\n",
            "[[2], [5], [17]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['doubt'], ['loaded language']]\n",
            "[[13], [2]]\n",
            "[['appeal to fear prejudice'], ['loaded language']]\n",
            "[[7], [2]]\n",
            "[['causal oversimplification']]\n",
            "[[6]]\n",
            "[['appeal to fear prejudice'], ['causal oversimplification']]\n",
            "[[7], [6]]\n",
            "[['flag waving'], ['loaded language'], ['reductio ad hitlerum'], ['slogans']]\n",
            "[[16], [2], [9], [4]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['causal oversimplification'], ['exaggeration minimisation'], ['flag waving'], ['loaded language'], ['name calling labeling']]\n",
            "[[6], [8], [16], [2], [3]]\n",
            "[['appeal to fear prejudice'], ['exaggeration minimisation'], ['loaded language']]\n",
            "[[7], [8], [2]]\n",
            "[['appeal to fear prejudice'], ['loaded language'], ['name calling labeling'], ['whataboutism']]\n",
            "[[7], [2], [3], [15]]\n",
            "[['appeal to fear prejudice'], ['loaded language'], ['smears']]\n",
            "[[7], [2], [5]]\n",
            "[['doubt'], ['whataboutism']]\n",
            "[[13], [15]]\n",
            "[['flag waving'], ['loaded language'], ['name calling labeling']]\n",
            "[[16], [2], [3]]\n",
            "[['loaded language'], ['name calling labeling'], ['whataboutism']]\n",
            "[[2], [3], [15]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['appeal to fear prejudice'], ['repetition']]\n",
            "[[7], [10]]\n",
            "[['loaded language'], ['whataboutism']]\n",
            "[[2], [15]]\n",
            "[['doubt']]\n",
            "[[13]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['causal oversimplification'], ['loaded language'], ['name calling labeling']]\n",
            "[[6], [2], [3]]\n",
            "[['appeal to authority']]\n",
            "[[19]]\n",
            "[['appeal to authority'], ['loaded language'], ['smears']]\n",
            "[[19], [2], [5]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['loaded language'], ['name calling labeling'], ['reductio ad hitlerum'], ['smears']]\n",
            "[[2], [3], [9], [5]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['doubt'], ['loaded language'], ['name calling labeling'], ['slogans']]\n",
            "[[13], [2], [3], [4]]\n",
            "[['glittering generalities virtue '], ['loaded language'], ['name calling labeling']]\n",
            "[[11], [2], [3]]\n",
            "[['loaded language'], ['name calling labeling'], ['slogans'], ['smears']]\n",
            "[[2], [3], [4], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['doubt'], ['loaded language'], ['misrepresentation of someone s position straw man '], ['whataboutism']]\n",
            "[[13], [2], [12], [15]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['exaggeration minimisation'], ['loaded language'], ['smears']]\n",
            "[[8], [2], [5]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears'], ['whataboutism']]\n",
            "[[2], [3], [5], [15]]\n",
            "[['flag waving'], ['loaded language'], ['smears']]\n",
            "[[16], [2], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['black and white fallacy dictatorship'], ['glittering generalities virtue '], ['loaded language'], ['smears']]\n",
            "[[0], [11], [2], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['exaggeration minimisation'], ['glittering generalities virtue ']]\n",
            "[[8], [11]]\n",
            "[['slogans'], ['smears']]\n",
            "[[4], [5]]\n",
            "[['exaggeration minimisation']]\n",
            "[[8]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['exaggeration minimisation']]\n",
            "[[8]]\n",
            "[['glittering generalities virtue '], ['loaded language']]\n",
            "[[11], [2]]\n",
            "[['exaggeration minimisation'], ['smears']]\n",
            "[[8], [5]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['slogans']]\n",
            "[[4]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language'], ['thought terminating clich ']]\n",
            "[[2], [17]]\n",
            "[['name calling labeling'], ['smears']]\n",
            "[[3], [5]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['causal oversimplification'], ['loaded language']]\n",
            "[[6], [2]]\n",
            "[['doubt']]\n",
            "[[13]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['appeal to fear prejudice']]\n",
            "[[7]]\n",
            "[['flag waving'], ['slogans']]\n",
            "[[16], [4]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['doubt']]\n",
            "[[13]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['appeal to authority'], ['loaded language'], ['reductio ad hitlerum']]\n",
            "[[19], [2], [9]]\n",
            "[['name calling labeling']]\n",
            "[[3]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['glittering generalities virtue ']]\n",
            "[[11]]\n",
            "[['appeal to fear prejudice'], ['loaded language']]\n",
            "[[7], [2]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['exaggeration minimisation'], ['glittering generalities virtue '], ['name calling labeling'], ['slogans'], ['smears']]\n",
            "[[8], [11], [3], [4], [5]]\n",
            "[['black and white fallacy dictatorship'], ['smears']]\n",
            "[[0], [5]]\n",
            "[['doubt']]\n",
            "[[13]]\n",
            "[['loaded language'], ['whataboutism']]\n",
            "[[2], [15]]\n",
            "[['causal oversimplification'], ['loaded language'], ['name calling labeling'], ['slogans']]\n",
            "[[6], [2], [3], [4]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['name calling labeling']]\n",
            "[[3]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['doubt'], ['loaded language'], ['name calling labeling'], ['smears'], ['thought terminating clich ']]\n",
            "[[13], [2], [3], [5], [17]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['appeal to fear prejudice'], ['loaded language']]\n",
            "[[7], [2]]\n",
            "[['flag waving'], ['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[16], [2], [3], [5]]\n",
            "[['flag waving'], ['loaded language'], ['smears']]\n",
            "[[16], [2], [5]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['doubt'], ['loaded language']]\n",
            "[[13], [2]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['name calling labeling'], ['smears']]\n",
            "[[3], [5]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['repetition'], ['whataboutism']]\n",
            "[[2], [10], [15]]\n",
            "[['exaggeration minimisation'], ['loaded language']]\n",
            "[[8], [2]]\n",
            "[['bandwagon'], ['loaded language'], ['thought terminating clich ']]\n",
            "[[20], [2], [17]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['name calling labeling'], ['smears']]\n",
            "[[3], [5]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['flag waving'], ['name calling labeling']]\n",
            "[[16], [3]]\n",
            "[['misrepresentation of someone s position straw man '], ['smears']]\n",
            "[[12], [5]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['repetition']]\n",
            "[[10]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['whataboutism']]\n",
            "[[2], [15]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['whataboutism']]\n",
            "[[2], [15]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['appeal to authority']]\n",
            "[[19]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears'], ['thought terminating clich ']]\n",
            "[[2], [3], [5], [17]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['appeal to fear prejudice'], ['doubt'], ['loaded language'], ['misrepresentation of someone s position straw man '], ['smears']]\n",
            "[[7], [13], [2], [12], [5]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['loaded language'], ['misrepresentation of someone s position straw man '], ['name calling labeling'], ['obfuscation intentional vagueness confusion'], ['whataboutism']]\n",
            "[[2], [12], [3], [14], [15]]\n",
            "[['loaded language'], ['name calling labeling'], ['slogans']]\n",
            "[[2], [3], [4]]\n",
            "[['appeal to fear prejudice'], ['black and white fallacy dictatorship'], ['exaggeration minimisation'], ['loaded language']]\n",
            "[[7], [0], [8], [2]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['name calling labeling'], ['smears']]\n",
            "[[3], [5]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['flag waving'], ['slogans'], ['smears']]\n",
            "[[16], [4], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['appeal to fear prejudice'], ['slogans']]\n",
            "[[7], [4]]\n",
            "[['doubt'], ['loaded language']]\n",
            "[[13], [2]]\n",
            "[['loaded language'], ['slogans'], ['smears']]\n",
            "[[2], [4], [5]]\n",
            "[['appeal to fear prejudice'], ['loaded language']]\n",
            "[[7], [2]]\n",
            "[['black and white fallacy dictatorship'], ['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[0], [2], [3], [5]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['doubt'], ['name calling labeling'], ['smears']]\n",
            "[[13], [3], [5]]\n",
            "[['doubt'], ['loaded language'], ['name calling labeling'], ['whataboutism']]\n",
            "[[13], [2], [3], [15]]\n",
            "[['exaggeration minimisation'], ['loaded language']]\n",
            "[[8], [2]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['doubt'], ['misrepresentation of someone s position straw man '], ['name calling labeling']]\n",
            "[[13], [12], [3]]\n",
            "[['loaded language'], ['smears'], ['whataboutism']]\n",
            "[[2], [5], [15]]\n",
            "[['thought terminating clich ']]\n",
            "[[17]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['loaded language'], ['name calling labeling'], ['whataboutism']]\n",
            "[[2], [3], [15]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['exaggeration minimisation'], ['loaded language'], ['whataboutism']]\n",
            "[[8], [2], [15]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['doubt'], ['loaded language']]\n",
            "[[13], [2]]\n",
            "[['doubt'], ['loaded language']]\n",
            "[[13], [2]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['appeal to authority']]\n",
            "[[19]]\n",
            "[['doubt']]\n",
            "[[13]]\n",
            "[['name calling labeling'], ['smears']]\n",
            "[[3], [5]]\n",
            "[['loaded language'], ['name calling labeling'], ['thought terminating clich '], ['whataboutism']]\n",
            "[[2], [3], [17], [15]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['doubt'], ['loaded language'], ['whataboutism']]\n",
            "[[13], [2], [15]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['loaded language'], ['slogans']]\n",
            "[[2], [4]]\n",
            "[['causal oversimplification'], ['doubt'], ['loaded language'], ['misrepresentation of someone s position straw man '], ['name calling labeling']]\n",
            "[[6], [13], [2], [12], [3]]\n",
            "[['obfuscation intentional vagueness confusion']]\n",
            "[[14]]\n",
            "[['loaded language'], ['name calling labeling'], ['slogans'], ['smears']]\n",
            "[[2], [3], [4], [5]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['repetition']]\n",
            "[[10]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['whataboutism']]\n",
            "[[15]]\n",
            "[['loaded language'], ['misrepresentation of someone s position straw man '], ['name calling labeling']]\n",
            "[[2], [12], [3]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['doubt'], ['loaded language'], ['name calling labeling']]\n",
            "[[13], [2], [3]]\n",
            "[['loaded language'], ['thought terminating clich ']]\n",
            "[[2], [17]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['appeal to fear prejudice'], ['loaded language'], ['name calling labeling'], ['whataboutism']]\n",
            "[[7], [2], [3], [15]]\n",
            "[['appeal to authority']]\n",
            "[[19]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['doubt'], ['loaded language']]\n",
            "[[13], [2]]\n",
            "[['doubt'], ['loaded language'], ['name calling labeling'], ['whataboutism']]\n",
            "[[13], [2], [3], [15]]\n",
            "[['doubt']]\n",
            "[[13]]\n",
            "[['name calling labeling']]\n",
            "[[3]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['doubt'], ['loaded language'], ['name calling labeling']]\n",
            "[[13], [2], [3]]\n",
            "[['name calling labeling']]\n",
            "[[3]]\n",
            "[['black and white fallacy dictatorship'], ['thought terminating clich '], ['whataboutism']]\n",
            "[[0], [17], [15]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['loaded language'], ['name calling labeling'], ['whataboutism']]\n",
            "[[2], [3], [15]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['doubt'], ['loaded language']]\n",
            "[[13], [2]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['exaggeration minimisation'], ['glittering generalities virtue '], ['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[8], [11], [2], [3], [5]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['slogans']]\n",
            "[[4]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['name calling labeling']]\n",
            "[[3]]\n",
            "[['doubt'], ['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[13], [2], [3], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['name calling labeling'], ['smears']]\n",
            "[[3], [5]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language'], ['slogans']]\n",
            "[[2], [4]]\n",
            "[['name calling labeling'], ['smears']]\n",
            "[[3], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['glittering generalities virtue '], ['loaded language'], ['name calling labeling']]\n",
            "[[11], [2], [3]]\n",
            "[['glittering generalities virtue '], ['loaded language']]\n",
            "[[11], [2]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['loaded language'], ['reductio ad hitlerum']]\n",
            "[[2], [9]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['name calling labeling'], ['smears']]\n",
            "[[3], [5]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['name calling labeling']]\n",
            "[[3]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['name calling labeling']]\n",
            "[[3]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['name calling labeling']]\n",
            "[[3]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['name calling labeling'], ['smears']]\n",
            "[[3], [5]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['name calling labeling'], ['smears']]\n",
            "[[3], [5]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language'], ['smears']]\n",
            "[[2], [5]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['smears']]\n",
            "[[5]]\n",
            "[['none']]\n",
            "[[1]]\n",
            "[['loaded language'], ['name calling labeling']]\n",
            "[[2], [3]]\n",
            "[['loaded language']]\n",
            "[[2]]\n",
            "[['loaded language'], ['name calling labeling'], ['smears']]\n",
            "[[2], [3], [5]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nEg:\\nour elders were called to war to save lives we are being called to sit on the couch to save theirs we can do this\\n[['appeal to fear prejudice'], ['causal oversimplification'], ['exaggeration minimisation'], ['slogans']]\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "cleaned_sentences, cleaned_labels = Dataset.preprocess(sentences, labels)\n",
        "\n",
        "# cleaned sentences contain the list of preprocessed sentences\n",
        "# cleaned labels contain the list of preprocessed labels for corresponding sentences (list of lists for each sentence.)\n",
        "'''\n",
        "Eg:\n",
        "our elders were called to war to save lives we are being called to sit on the couch to save theirs we can do this\n",
        "[['appeal to fear prejudice'], ['causal oversimplification'], ['exaggeration minimisation'], ['slogans']]\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cleaned_sentences[3])\n",
        "print(cleaned_labels[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdltVpKI_d3q",
        "outputId": "19d18707-a7e4-4577-9b41-9f54c908d371"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pathetic the cowardly asshole weak failure impeach it again 45 the coward s afraid of strong women politicususa com childish trump won t meet with pelosi on coronavirus because he doesn t like her \n",
            "[[6], [2], [3], [4], [5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284,
          "referenced_widgets": [
            "3340db535a734544b6fe1e1974d0ea9a",
            "d3d218d37241457885e33760c15a3d41",
            "79e446fd9e3644fdbacdfeaf7dab763c",
            "3b502b16000a456c9fbafb38b0c22b47",
            "c9eed52e69c94fa88d09fa75c70a2b45",
            "c280541c73294c3cb9f6bafac567af97",
            "2ba377279f18464d8eba9bc9dcc567d5",
            "e476fbf237234c839da9e4ea98d467a3",
            "08e8e779ee804f7381a249c9330faeff",
            "d371ef176e0043019397ea6135171c10",
            "db4097ed29b84257a52c326328f410ab",
            "3221acf9214c4eee84277a0aea8ee5e8",
            "c5993a4b83b54f62a5640826084e76f8",
            "0132c2e08f6645f9b7dbd0546cc58a75",
            "49900eb453234c46b012e5ad1600efbb",
            "a8f26977cce74e61978a4f254b4d33a5",
            "fccc6c8ead264760828832a8987d0f07",
            "3d88c1b8ba9e49c6a8c69a9df028a389",
            "4529b092309343e68781ef6e617462df",
            "e2f83a4051794078a64af92033532fb7",
            "b39ac3f46afa4d3fb9df7931f30fa264",
            "422bfc40a298424a83d869b7bea1342a",
            "5dc07ce609f1443dac4f9e319bb7b41a",
            "76d2ae9a0c12454aa52be56863213c97",
            "a6265d2968c448689a73a68f0fd7c173",
            "26c0be618fad4a12a692a8db6c73d857",
            "9d7240ab80d84dfbb2a5ce1791588862",
            "7b985d0a70a4477c9fc71f03d42f9947",
            "aed466573c6248689b69868f851d36fd",
            "6ebe34fe76ac4ba8abaad54ddfd0c0db",
            "7bfa50c5ac954405a2a82a8fcda09799",
            "bf58088026b54126935899029a0717c3",
            "3c395f51f48d410693a9805002b6bc29",
            "149ccabb4f884310bd4bf83c89786f97",
            "3365ec5bacca4f298f6a98513c34fc60",
            "d31e1d71db0747749d46ad3263e6ba3e",
            "8190f8e2646243a3aa331fa9da3f53f9",
            "86715bab2c1d4e178550f70293b1d8dd",
            "1af1d3da999241beb6edca5d9be0e5ed",
            "7427c05a56e14db1bee23faf2021a42f",
            "e946de4597914c62a5c26905b4d427f0",
            "2752817ab2074c54b1080294a42851ff",
            "192e616e76a64a4c83a2194ce99d8b72",
            "95e4f960cfcb42a79459d76e505606e1",
            "1dd19af7296d4e07a12e306e2222f022",
            "f05592e383e24b11b76d5ace879f838f",
            "ae01135e8bc74a0ab5af2f8b7dafe87f",
            "a3b10fb125a74d69a6195e05a63aeb72",
            "5ffe8fbb9dbe472a87a939aff9b98a09",
            "9318bef1144248549d4488322471261f",
            "35082f1d95984ed9b3b9bda6f6fac733",
            "01bd41b684ce481a994f599a214abeeb",
            "a8e184e22e344bce9dea778744be842a",
            "4ddb7c2b376748ef838460dc65f5640a",
            "60a14a0c009945db8d2796a013457b37"
          ]
        },
        "id": "sUqltyHAEUCd",
        "outputId": "9e5dab13-a566-4b35-cc75-08fbeaa9a22f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3340db535a734544b6fe1e1974d0ea9a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3221acf9214c4eee84277a0aea8ee5e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5dc07ce609f1443dac4f9e319bb7b41a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "149ccabb4f884310bd4bf83c89786f97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1dd19af7296d4e07a12e306e2222f022"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "model_name = 'bert-base-uncased'\n",
        "model = TFAutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = cleaned_sentences[0]\n",
        "print(text)\n",
        "tokens = tokenizer(text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFcJY-LOYTmN",
        "outputId": "706d1d44-2075-4d4b-e27f-a5779e62e689"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "there are only two genders female male \n",
            "{'input_ids': [101, 2045, 2024, 2069, 2048, 5907, 2015, 2931, 3287, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cleaned_sentences)\n",
        "print(cleaned_labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrwqWUEhupk0",
        "outputId": "e24bb594-f2c6-4798-c8cb-6ee1321af88f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['there are only two genders female male ', 'this is not an accident ', 'so bernie bros haven t committed violence eh power comes from the barrel of a gun comrades what about the one who shot congressman scalise or the dayton ohio mass shooter ', 'pathetic the cowardly asshole weak failure impeach it again 45 the coward s afraid of strong women politicususa com childish trump won t meet with pelosi on coronavirus because he doesn t like her ', 'who trump represents who democrats represent ', 'our elders were called to war to save lives we are being called to sit on the couch to save theirs we can do this ', 'adolf hitler believed state power would fix germany proposed gun control promised a political revolution called himself socialist blamed jews for germany s problems wanted a heavily regulated economy bernie sanders believes state power will fix america proposes gun control promises a political revolution calls himself socialist blames the rich for america s problems wants a heavily regulated economy', 'calm down little trump hater i found your binky ', 'ugly inside out racist liar with no ethics and he s nuts dangerously stupid and certifiably crazy ugly inside out', 'when your taxes are finally used to kill terrorists instead of funding them trump 2020 ', 'scare tatics by the left close businesses close stadiums destroy the stock market try to eliminate trump rallies is this part of a larger conspir cy coronavirus don t panic think america ', 'those liberals hate me it s because i m black isn t it ', 'if you think they are hiding the cure for cancer but you discourage people from getting the hpv and hep b vaccines then you are they ', 'a society that keeps cures a secret in an effort to sell medications for huge profits is not a civilised society it is a mental institution ruled over by phsychopaths ', 'its not the hero we need but the hero we deserve ', 'trump cures coronavirus curing corona virus is racist we have the right to die from our coronavirus democrats are outraged ', 'un new york un office recruits paramilitary troops for disarmament and reintegration of us civilians welcome to america ', 'hiroshima 1945 2016 detroit 1945 2016 moral of the story it s easier to come back from a nuclear bomb than decades of democratic leadership ', 'reminder this building in oklahoma city was blown up and destroyed just 4 days before hillary clinton was to be indicted in the whitewater scandal all documents lost ', 'how to tell if your dog is involved in a sex scandal ', 'i promise i promise i promise i deliver ', 'the people who once called our soldiers baby killers now march for the right to kill babies ', 'democrats started wearing all white again', 'all i want for christmas is justice ', 'leftists think injecting cattle with hormones is evil but think injecting kids with hormones to change their gender is just fine ', 'correct the world china ', 'i hate trump most terrorist do', 'the most costly errors in all of history world health organization who preliminary investigations conducted by the chinese authorities have found no clear evidence of human to human transmission of the novel coronavirus 2019 ncov identified in wuhan china 14 jan 2020 world news february 3 2020 10 33 pm 2 months ago who chief says widespread travel bans not needed to beat china virus ', 'covid 19 is everywhere but countries with heads of state managing the crisis better seem to have something in common germany new zealand belgium finland iceland denmark ', 'people keep asking why did god turn his back on america he didn t america turned her back on god this is what the world looks like without him ', 'couldn t wash hands is now extinct ', 'what kids think communism is what communism really is ', '8 years under obama 4 million jobs lost unemployment peaked to 9 9 gdp down 2 8 2 1 2 years under trump 5 1 million jobs gained unempl fell to 3 6 gdp up 3 2 ', 'the two biggest threats to america the worst senate leader ever and the most corrupt president ever ', 'this is your child with whooping cough vaccinate your children now ', ' yes mr trump let s make america great again but first get one thing straight america was great before you were elected barbra streisand ', 'it was never about the virus it s about seeing how far we can push you before you push back ', 'how dare you not voterino for heckin bernerino don t you know that a vote for biden is a vote for fascism the world is literally dying and bernie sama is the only one who can save it haha hey its the obama guy ridin with biden 2020 ', 'killed thousands of innocents with drone strikes received a nobel peace decided not to retaliate and kill 150 people over an unmanned drone called a warmonger ', 'spelling lesson the last 4 letters in american i can the last 4 letters in republican i can the last 4 letters in democrats rats ', ' if you tell a lie big enough and keep repeating it people will eventually come to believe it joseph goebbels nazi propaganda minister the new york times cnn bbc time msnbc nbc los angeles times fox news channel npr abc cbs news the washington post usa today ', 'must be an election coming democrats are visiting black communities again ', 'deaths in the u s during a 10 year period 2004 to 2015 due to measles zero source cdc due to measles vaccines 108 source vaers database ', 'democrats have outright stated that they will obstruct everything the republican president does even if it means harming america they have put party before country and it is unacceptable ', 'the democratic party is the party of crime evil a terrorist organization who hates america americans traitors to america the communist party save america support trump ', 'don t forget that in january trump formed the coronavirus task force the dems were wasting time on a sham impeachment ', 'till death do us part no to violence against women ', 'if y all liberals want to tear down monuments to slavery racism i have just the monument for you democratic national headquarters 430 south capitol street ', 'if trump isn t hitler then l m a moron self awareness ', 'i m not pregnant i haven t been tested but the president says if it s not tested it s not real i think it s gas ', 'history has shown that these are the first two things banned by totalitarian governments', 'if we divide 125 genders by three bathrooms how much climate change do we have ', 'finished 4th in lowa behind an old communist a gay guy and a fake indian there s nothing quite like getting your ass beat by the village people ', 'do you remember when swine flu ebola virus and zika virus caused mass cancellations crashed our stock market caused confusion from misinformation drove people to stockpile toilet paper of course not because obama handled that shit ', 'former presidents can be impeached impeach obama ', 'the real virus threatening america ', ' if a law is unjust a man is not only right to disobey it he is obligated to do so thomas jefferson ', 'the bulge in conservative girls pants is a gun the bulge in liberal girls pants is a penis ', 'transgender man gives birth to non binary partner s baby with female sperm donor if i didn t see it it didn t happen ', '21 people running for president and only 1 stands against killing babies ', 'hillary clinton joe biden weekend at bernies s he may be dead but he s the life of the party ', ' people are dying who have never died before donald j trump march 18 2020', 'the party of diversity black woman black black samoan woman mexican old white millionaire fake mexican mostly gas galaxy dust taiwanese gay old white millionaire', 'elegant at lying brutal with the truth ', 'this is the difference between 1 4 gdp and 4 1 gdp ', 'what a contrast from worst ever to best ever', ' socialism only works in two places heaven where they don t need it and hell where they already have it ronald regan ', 'that s a fact did you know the nra trained black americans to fight against the democrat formed group the kkk ', 'traitors moscow mitch moscow s bitch ', 'pedo trash pretending to be libertarian people that understand consent the fuck outta here ', 'i didn t know there was a sexual predator award thanks democrats ', 'when you re anti trump but you re pro rapist they all knew and ', 'keep in mind that democrats voted to fine american citizens for not buying insurance and then conspired to give it to illegal aliens for free ', 'i ll never forget who did this no matter how much facebook defends them ', 'democrat party nbc cbs msnbc cnn ', 'a journalist asked justin trudeau when more help would arrive for seniors he answered by saying the priority was on helping other groups of canadians first ', 'guess who s waiting for someone else to do all the work lol bernie ', 'liberal logic don t call them animals don t call them people ', 'why do liberals fight to ke these and fight to kill these ', 'patriots which group held the country s interests over their own personal gain parasites ', 'coward american ', 'acquiring immunity the natural way acquiring immunity through vaccination which would you choose ', 'trump reportedly offered a german firm 1 00 000 000 for exclusive rights to any coronavirus vaccine trump wanted not only to control any new vaccine but also to make sure that it would only be available on a for profit basis reported common dreams what could be more depraved than trying to profit off of the suffering of the entire world spread his shame ', 'free speech hate speech someone explain this shit ', 'if you put hillary s arrest on pay per view you could settle the national debt ', 'hi i m george soros a billionaire sociopathic globalist i destroy economies cultures countries i profit off of the destruction of entire societies i finance black lives matter riots i am funding antifa', 'vote it out vote it out he said it wasn t real he said it s contained he said it would disappear he blamed democrats he shared his hunches he overruled his scientists he has failed he has endangered every one of us vote it out vote it out ', 'democrats then democrats now ', 'harry s truman you can t get rich in politics unless you re a crook we know ', 'i have a chance to be the first gay united states president ahh excuse me ', 'truth is hate to those who hate the truth truth is love ', 'the real virus threatening america ', 'this iconic photo of two boys one vaccinated against smallpox and one who hadn t been vaccinated was published in 1901 and taken by dr allan warner at the leicester isolation hospital ', 'on tuesday november 3 2020 we make america great again by voting this nightmare out of office ', 'at last the illegals and economic deadbeats and parasites have a president on their money u s department of agriculture food coupon value 1 dollar non transferable except under conditions prescrided by the secretary of aqgriculture ', 'isis employee of the month ', ' if that fuckin bastard wins we re all going to hang from nooses you better fix this shit hillary clinton email to donna brazile dnc chair october 17 2016 ', 'the axis of evil of the united states of america ', 'what people think super heroes look like what super heroes actually look like ', 'i get what i want or the country doesn t get what it needs ', 'we owe illegals nothing and our veterans everything', '2016 i ve tried to fix the economy for 8 years nothing can fix it trump can t fix it 2019 trump didn t fix the economy i did it was my work that fixed the economy like i planned 2020 corona didn t tank the economy trump did nothing can fix it now trump can t fix this ', 'what covid 19 protesters think we see what we really see', 'its nice to have a president with balls and a 1st lady who doesn t ', 'it s not that the majority are silent it s that the media are silent about the majority ', 'if you support this man i won t judge you for your choice of political parties i will judge you for your lack of morals ethics and humanity so will others so will history ', 'for the love of god arrest somebody ', 'you d think you were in a whore house seeing this many pussies ', 'storm forming in gulf blame trump expect dems to castigate him for this too ', 'charles wade blm co founder was arrested in 2016 for child sex trafficking in other words he was arrested for modern day slave trading i hope the irony has not been lost on you ', 'how i feel after debating anti vaxxers', 'surgeons operating with a mask on for 20 hours karens shopping with a mask on for 20 minutes', 'hostess official campaign sponsor for ding dong ho ho ', 'i like presidents that don t lose money ', 'its been confirmed bill gates has developed a facial recognition system that can detect unvaccinated individuals the only way to block it is to wear a face mask', 'trump promised to make america great again four years later pandemic recession mass unemployment riots winning', 'the real reason you re not paying attention to the childrenslivesmatter or endchildtrafficking movement is because the mainstream media haven t told you to ', 'what type of leader do you prefer justin trudeau at 29 erin o toole at 29 ', 'this is what stupid looks like ', 'starbucks is now offering these free islamic donuts to your kids the text calls for shakira law in america', 'doll represents how many vaccines a child receives by age 2 any questions yes we do have a question each doll represents 10 000 children killed by vaccine preventable diseases every year why don t you want to prevent diseases that kill ', 'happy fathers day ', 'anti vaxxers say the brady bunch measles episode is proof that measles was no big deal if you have to get sick sure can t beat the measles by that logic hogan s heroes is proof ww2 pow camps were all just shits and giggles ', 'first photo of the russian vaccine smirnoff vodka ', 'better to wait in a long line to vote for trump now than to wait in long lines for food in a socialist america', 'don t trust bigpharma read the insert the inserts are written by bigpharma', 'all the squawking about nobody on the left showing empathy for trump s covid diagnosis tell you what when he shows an ounce of concern for these kids we ll think about it ', 'antivaxxers like to say diseases were ended by improved sanitation lets take a look at some places where diseases have been eradicated this is a low income area of mumbai india where no one gets polio anymore ever isn t it amazing what sanitation can do ', 'i ve served this country for decades what is china', 'the democrat ticket is biden harris stop you re gonna make me pee ', 'finally proof found that vaccines contain mercury x3 magnification x30 magnification x300 magnification ', 'do you know any democrat who is enthusiastic and inspired that this is their nominee and thinks this is the best and the brightest they have to offer ', 'okay but how will anyone know if they lose their sense of taste ', 'the corrupt bunch ', 'this is how thousands were murdered by our government tied to chairs denied family visits alone abandoned what should we do to the government ', 'don t forget to tell your surgeon not to wear a mask the next time you need an operation because apparently masks are ineffective at protecting against germs and you definitely don t want your surgeon deprived of oxygen', 'to help donald trump get the full covid 19 experience let s make sure he loses his job and is evicted from his home next month ', 'the law is not a moral compass the people who hid anne frank were breaking the law the people who killed her were following it ', 'no honor no integrity no principles no morals no patriotism no honesty no ethics no character no decency no virtue no scruples no class no humanity 100 turd', 'anti maskers god', 'if we give up everything that offends someone this will be the only flag we can fly ', 'if the blitz happened in 2020 i don t consent to this new normal there are no bombs you ve been brainwashed i m going outside its my right they want us to stay here to control us i m leaving the lights on in my house and you cant stop me', 'i remember it all so clearly the entire family committed sexual misconduct on me against my wishes ', 'hey everyone check out cokehead neil terell perfect example of the washed up broke liberal ', 'which one are you choose wisely before they choose for you', 'if amy coney barrett doesn t have the common sense to avoid bringing her 7 kids to a maskless non socially distanced event then she doesn t have good enough judgment sit on the supreme court full stop ', 'before my presidency there was no blm there was no antifa there was no war on police i built that ', 'americans when newton discovered gravity gravity is communist we will not fall down with 9 8m s 2 y mass my choice', 'hey liberals we changed the flag for you like it trump 2020 keep america great ', 'its time to take astand folks either you let them ban cops tear down history and subvert you into sniveling cowards or stand up and tell them to fuck off ', ' kenosha mile challenge run 684 ft all alone at night being chased by a violent mob have no gear no spare mags no backup no moral patches be attacked and defend yourself killing only felons harm no others proceed directly to the police taking responsibility for your actions be witch hunted as a murderer while your country is burning in riots first completed by kyle rittenhouse age 17 ', 'trump', 'special edition democratic national convention 2020 americas most wanted where all the crooks come out ', 'has worked a total of 12 days during the 90 day pandemic so far resign you re pathetic ', 'some americans worry vaccines will have microchips to track them their phones ', 'trudeau s priorities 1 enriching his friends and family 2 other liberal elites and lobbyists 3 foreign dictators 4 corrupt corporate executives erin s priorities 1 canadians ', 'if you dont listen to despacito you ain t latino ', 'the jig is up the entire world knows the truth donnie behind all that anger was a sad little failure of a man who turned everything he touched into shit ', 'dad what s losing like i don t know son i m a trump supporter', 'in 2021 people who are currently opposed to a non existant covid vaccine will tell you think for yourself and to do your own research ', 'imagine if 50 million babies were allowed dying wishes ', 'mitch mcconnell 2016 the american people should have a voice in the selection of their next supreme court justice this vacancy should not be filled until we have a new president if you think mcconnell will follow his own advice you must be a special kind of stupid ', 'imagine the possibilities if they were to put this much effort into cleaning up blighted communities ', 'venezuela s communist dictator nicolas maduro blm founder opal tometi', 'reportedly donald trump lost 1 17 billion from his businesses over 10 years from 1985 to 1994 you re fired so basically trump isn t actually a successful businessman but he played one recently on tv ', ' i am enthusiastic for this ticket no one ', 'can you still get regular sick or is everything corona ', 'anyone else want their ass handed to them ', 'pray for this man he s fighting a evil that we can t even imagine ', 'it s obvious i haven t been in a beauty salon lately and besides they don t work on wigs ', 'the shocking truth doctors don t want you to know research proves homeopathy cures three conditions low glucose levels thirst heavy wallet syndrome', 'breaking tonight on fox geraldo opens the vault where trump keeps his healthcare plan spoiler it s empty ', 'they say you can t fix stupid turns out you can t quarantine it either ', 'whoever replaces ginsburg raped me in high school ', 'this is the leading cause of death in the united states ', 'one of the hardest most ferocious fighters the world has ever seen and mike tyson ', 'here s new conservative leader erin o toole and justin trudeau at roughly the same age o toole signed up for the canadians forces while trudeau was a part time ski instructor living off a multi million dollar trust fund o toole understands regular canadians because he s always been one of them trudeau will always be out of touch ', 'parents refusing newborn vitamin k shots because they d prefer baby have an all natural organic intracranial hemorrhage', 'wait what are you doi putin shall be the eternal leader of this world ', 'burger king forget about the presidency for a moment trump s behavior would get him fired from applebee s ', 'its time to disband the federal goverment change my mind ', 'it is better to remain silent and be thought a fool than to display one of these on your lawn and remove all doubt biden president ', 'an irresponsible president an irresponsible man ', 'hairgate might have been bargate were it not for this woman misreading the sign on the door salon and saloon look very similar to 80 year old eyes ', 'federal election western canada territory votes ', 'find the differences in these two images ', 'if the media will lie about this what else are they lying about ', 'you decided not to vaccinate classic mistake ', 'trump leaving the hospital covid free ', 'democrats head for the early voting precincts ', 'presidential debate via satellite joe biden', 'hmm this bridge is only 99 997 safe i think i ll swim antivaxxerlogic', 'they told me i could be anything i wanted so i became the savior of western civilization', 'today s covid numbers are ', 'warning vaccines may cause loss or greying of hair wrinkles grandparentage free or reduced price bus passes telling kids to get off your lawn moaning about modern music', 'let s give all police officers 30 days paid vacation to be taken simultaneously so idiots like those pictured below can get a taste of what it d be like to have no cops on duty defund the police ', 'are you getting your shingles vaccine no did you receive a shingles vaccine no ', 'and just like that trump got the rona and beat it over the weekend ', ' it s a shame that a leading transparent western free market oil and gas producer that was already very focused on esg is going to be taken offline and their barrels are going to be replaced by barrels of opaque state controlled oil from wherever i can just see the russians rubbing their hands saying this is fantastic peter terzakian arc energy research institute ', 'conspiracy theories because sane logical explanations aren t as much fun as ignorant fear mongering lunacy', 'the ideology that killed over 100 million last century is now being praised at our universities today sa socialist alternative the university of melbourne i want full communism because i value a fair society socialist alliance australian national university ', 'the royal canadian mounted police we always get our man unless that man is a high ranking liberal politician that s when we go into hiding ', 'when a liberal starts talking', 'how could you have married that man i was going to ask you the same question ', 'they should first test the covid vaccine on gov t officials if they are safe the vaccine is good but if they die the country is safe ', 'our constitution was written to stop people like these', 'when you are so full of shit that you need a second asshole', 'breaking massive crowds at biden s rally', 'the first president to ever fight child sex trafficking if that doesn t earn your vote nothing will', 'trump said they are fighting an ancient sex trafficking ring and not a single reporter asked for more information ', 'i bullshitted and used blacks and minorities to get elected and did nothing for them now i m endorsing joe biden to do the exact same thing ', 'the first black woman vice president and her family ', 'who shit my pants ', 'joey have you ever rubbed the blonde hair on a grown mans leg ', 'still your president', 'me name your high level sources lib journo ', 'donald how do you sleep at night knowing how many people hate you naked with a super model and it s mr president to you ', 'the moment you regret the transition surgery', 'i bet he s thinking about another woman why haven t they arrested her yet ', 'the picture they show you when you have an erection lasting more than 4 hours ', 'if trump serves a total of 8 years he will have donated his salary of 3 200 000 the most honest man in washington ', '47 months vs 47 years you decide who got more done and who is the problem', 'it s just a debate come on joe you can do it ', 'non essential employee of the month 48 years in a row', 'oh shit look at that we all get treated the same way who knew', 'defamed by cnn sues cnn wins then roasts cnn on cnn', 'the first black lives matter meeting ', 'the political party who lost 33 000 emails wants mail in voting ', 'listen up group give me a thumbs up if you want the village idiot alexander booted', 'trump loves miners biden loves minors ', ' aby s lives matter', 'if the democrats really were for women and minorities why did they put an old white guy on top and make her serve him that sounds extremely racist and sexist doesn t it ', 'which america will you vote for biden trump', 'snowflakes begging this guy to save them from trolls the rest of earth', 'breaking news shit floats ', 'i can t breath in this thing you have no idea how hard this is laughs in mopp 4 ', 'proof you don t have to fly a plane into a building to destroy a nation ', 'biden part of the problem since 1972', 'trump did it cnn', 'the democratic party we run cities into the ground ', 'preparing joe biden for a q a', 'i just tested positive for a second term ', 'i heard y all don t want me moderating anymore is that true ', 'chris wallace is a disgrace and should not moderate another debate again ', 'worst moderator ever ', 'do you think chris wallace will be fair to president trump ', 'who else is looking forward to me beating sleepy joe in the debate ', 'if they can impeach him in an election year he can pick a supreme court justice ', 'we can survive without the american athlete but not without the american soldier', 'would you trust me ', ' if you can protest in person you can vote in person trump do you agree ', 'when you see the guy who said you ll never be president at your inauguration', 'so they protest in person against voting in person postmaster saboteur', 'do y all really want us to retire ', 'would you ever vote democrat to run your city ', ' i stand for the flag because i am a proud american stephon tuitt pittsburgh steelers ', 'that face you make when criminals are questioning your integrity', 'states of america used to think trump was great but now seeing the whole system was rigged against him i have to believe now that he is one of the greatest of all time ', 'it does not matter what dems hollywood elites and media pundits say i trust our president and will vote for him again ', 'the united states of america should be a sanctuary for law abiding americans not criminal aliens ', 'in a show of hands who s still voting for me in 2020 ', 'he knew he was entering a den of vipers and he went in anyway for us are you thankful for trump ', 'happy 4th patriots make america great again ', 'michigan governor whitmer is now asking for washington s help with her budget i don t think president trump should give her a single dime do you agree ', 'there is no comparison between pat tillman and colin kaepernick ', ' never take a knee only to god president trump', 'we went from the worst president ever to the best president ever who agrees ', 'make aoc bartend again ', 'the mayor of minneapolis wants 55 million dollars for damages caused by riots i don t think he should get a penny do you agree ', 'president trump says he will designate antifa as a terrorist group do you agree with him ', 'nancy thinks this is morbidly obese what do you think ', 'when did america stop being great when this clown was elected twice ', '78 year old virus still no cure ', 'hope you had fun investigating me now it s my turn', 'if you would like to see adam schiff tried for treason give a yuge thumbs up ', 'impeach trump before we all end up with jobs ', 'election is only 6 months way thumbs up for trump and thumps down for biden ', 'i still don t understand how a man who s never held public office until being elected president is blamed for all of america s problems by the people we ve had in congress since the 1970 s ', 'we the people want this woman out of office', 'knock knock who s there who s where ', 'i picked you for president', ' american warriors did not defeat fascism and oppression overseas only to watch our freedoms be trampled by violent mobs here at home president donald trump', 'house majority whip james clyburn gave it away with one comment covid 19 is a tremendous opportunity to restructure things to fit our vision ', 'nike called and said they were being looted by black lives matter i told them to call the nfl for help ', 'the party that constantly calls the right racist and sexist just chose their vp based on race and sex ', 'what does a government do once it has disarmed its citizens whatever it wants ', 'that look you get when your billion dollar virus has a 20 cure ', 'if we were really wrong about them they wouldn t need to censor us', 'it s no longer democrat vs republican it s communism vs freedom', 'lockdown is the only way to keep you safe really ', 'which political party are the good guys it s the one that doesn t support burning our cities releasing convicted criminals attacking the police and silencing free speech ', 'on the same day president trump expanded education and economic opportunities to hispanics the left launched a boycott against a hispanic owned family business for supporting trump', 'this is not baghdad this is not benghazi this is not fallujah this is minneapolis ', 'remember those kids at the grocery store sitting in the basket screaming and yelling and beating on stuff in a total meltdown and their parents stood there and did nothing we said god help us when they grow up well they ve grown up ', 'a true new york city nitwit he screws up an entire state in over a 9 year period and then has the nerve to say that the president is not doing enough ', 'for anyone wondering if trump knows he knows ', ' he told us to protect our borders he told us to bring manufacturing back home he told us to be less dependent on other countries he warned us about china democrats fought him every step of the way ', 'as a taxpayer and citizen of this country i do hereby demand the arrest and conviction of senator chuck schumer for his threats to the supreme court ', 'boys imma need those pens back ', 'when a republican is in the oval office they all want to be bob woodward when a democrat is in the oval office they all want to be monica lewinsky ', 'in my day you were either pro america or a commie you can call yourself liberal progressive or socialist but you re still nothing more than a rotten commie ', 'how much less diverse is the 2020 dem field from the 2016 gop field white white white white white white cuban black orange cuban canadian wood ', 'we weren t notified before the attack on soleimani neither was he ', 'bernie we just promised to withhold aid from israel unless they change their stance on gaza thats quid pro quo like what were are blaming trump for and we just openly declared it democrat voters are too stupid to figure it out right ', 'let me get this straight biden blackmailed ukraine with a billion in tax dollars to drop an investigation into his son and democrats want to impeach president trump for simply asking if it was true ', 'whats the difference between a liberal and a puppy after a few weeks the puppy quits whining ', 'the choker ', 'the guy telling us the russians hacked the election also told us the nsa was not spying on americans ', 'does this upset you then you re the racist ', 'do you agree with president trump when he told ilhan omar she should get out of america and said you can t leave fast enough ', 'i passed a law in 1996 that separates kids from parents who enter the u s illegally i enforced the law he passed for two terms isn t it hilarious that democrats are demonizing me for enforcing their law ', 'and then i told them my wife lives in a gated community ', 'l ll tell you what a constitutional crisis is 22 million illegal aliens living in america utilizing benefits they never contributed to voting illegally yes this is a real constitutional crisis ', 'oh look over there smoke signals it says you have a 1 1024th chance of being president ', 'remember that the same people who told you trump would start a nuclear war are now the same people upset over peace ', 'we voted not guilty in the clinton impeachment trial after the fbi found clinton s dna on monica s dress we dont let fbi findings influence our votes ', 'liberals be like trump spoke in favor of oxygen today ', 'everything liberals are offended by volume one ', 'if he was alive today he would walkaway from today s democratic party ', 'illegals aliens come before americans in the democrat party you own it chuck schumershutdown ', 'donald j trump puts up halloween decorations inside the white house spooky af ', 'too bad there are no electoral votes in the state of denial ', 'unarmed vicitm armed victim any questions ', 'this is what happens after they take away all of your guns ', 'its obvious i m lying and i know that i am but it s sexist for you to point it out or tell the truth go lay down ', 'if you don t vote for me i aint black ', 'on a positive note nobody has died of old age since march ', 'i may be running for vp but y all know damn well im in charge im comin 4 your guns ', 'hold on to your rifles their magic must be very powerful or politicians wouldn t want them so badly ', 'the only reason why the government would want to disarm you after 243 years is because they intend to do something that you would shoot them for ', 'the police are the enemy absolutely defund them words only a criminal would say k the blue trump 2020 keep america great ', 'liar liar 2020 remake staring joe biden i m kickin my ass do ya mind ', 'peaceful protesters we re getting blamed for the actions of violent looters gun owners first time ', 'this is my trade deal for your mandatory vaccine f k your 6ft ', 'me waiting for that mandatory vaccination ', 'we have unfortunately reached the point to where these are the only votes that will make any real difference ', '238 years ago we froze and starved in order to defeat the largest military force on earth to build a free nation and you surrendered it because you re afraid of getting sick ', 'gun control it only ends well for those who control the guns ', 'liberals say if confiscating all guns saves just one life it will be worth it well then if deporting all illegal aliens saves just one life wouldn t that be worth it ', 'there s a reason you separate military and the police one fights the enemies of the state the other serves and protects the people when the military becomes both then the enemies of the state tend to become the people ', 'healthcare is a right and the government should pay for it guns are a right should the government pay for them too ', 'america was founded by tough hell raisers rugged citizens who evaded taxes spoke strongly against tyranny grew tobacco brewed beer and spirits and smuggled weapons and it will be saved only by those same types of citizens ', 'anti trumpers june 2019 trump is weak for not starting a war with iran anti trumpers january 2020 trump is trying to start a war with iran ', 'hey nancy yeah its me adam call soros i need to order a school shooting this impeachment hearing b s just blew up in our faces we need a distraction ', 'control education control their minds control healthcare control their bodies control the media control their thoughts control the votes control their lives those we can t control we must destroy ', 'saying that guns cause murders is like saying steering wheels cause car wrecks ', 'while the virginia governor credits his extra police force for the total lack of violence he forgets his forces were outnumbered and out armed hundreds to 1 if the citizens wanted violence they would have done it ', 'hi my tv keeps making this repetitive whining noise i was wondering if you could help me that s probably just adam schiff ma am try turning off the impeachment trial ', 'saying you are a patriot is not enough you have to be one ', 'my parents were killed as a result of a gun free zone i carried a gun at all times till it was made a felony to carry in certain areas a man with a gun started shooting people i had the perfect shot but was disarmed by laws ', ' to conquer a nation first disarm it s citizens adolf hitler i933 ', ' quite frankly having adam schiff lecture the senate about fairness and due process is like listening to an arsonist talk about fire prevention senator lindsey graham ', 'it s not just that i care about my right to own a gun and protect my family it s also that i question your motivation for trying to stop me from being able to do it ', 'ca ny ca ny ca ny why we have the electoral college ', 'my greatest wish right now is for trump to get better and donate plasma so a treatment can be developed and the libs can be saved by trump s blood ', 'dementia my ass i ve always been this dumb ', 'joe biden preparing for the debate with trump ', 'i was raped by amy coney barrett cnn', '42 days until not my president season 2 starts i love that show ', 'check out target s new uniform i m officially never shopping there again ', 'losers can keep watching sweaty nfl thugs supporting rapists and blm il stick to watching the gorgeous babes playing beach volleyball ', 'select all the squares with peaceful protests ', 'drew brees went from saying he would never kneel for the anthem to wearing the name of a man who sexually assaulted a woman this is bowing to the mob this is a coward ', 'is this even slightly appropriate in a public school let s talk because this has become a pervasive issue affecting our kids black lives matter ', 'she s like a beautiful tiger in the wild gorgeous piss her off by challenging her intelligence and you ll see what terror really is ', 'vote joe and the ho 2020 ', 'when nobody knew who you were until you got on your knees', 'so kamala voted to convict trump for the crime that joe bragged he committed ', 'biden chooses kamala harris to lose election with him ', 'i had them believing i m an indian that s nothing liz they think i m african american ', 'government has failed you i ve been in government 49 years ', 'we have hillary s 30k emails lets open one ', 'when you insult trump you insult 65 million americans ', 'over my dead body will trump win a second term ', 'your suffering is not my problem you get nothing until i get what i want ', 'trying to find the part in the constitution about death bed wishes ', 'one life taken ruth bader ginsburg billion lives saved ', ' only make the vaccine in suppository form i want the democrats to shove it up their asses ', 'good job rapist visits jacobs but not the two officers that were shot ', 'democrats think hating their own country is a good campaign strategy ', 'i endorse you joe hey thanks 0 j ', 'you can either vote for the man that bangs pornstars and supermodels or vote for the man that gropes feels up and sniffs little girls ', 'who wants to see this become a reality ', 'imposter everything this man has told you about himself his birth certificate his ss his schooling his commitment to the well being of this country his religion everthing is a lie ', 'i am going to be the first president in history to put a person that committed treason in jail obama ', 'never forget what they did to this man we owe the left nothing fill the seat ', 'cnn reports record 15 000 submarines shown here showed up in support of joe biden this has to be troubling for the trump campaign ', 'whenever i think i have had a horrible day at work i remind myself that nancy pelosi has a gynecologist', 'best trade ever ', 'i don t always get impeached but when i do i get nominated for 2 nobel peace prizes and get reelected ', 'joe biden s teleprompter is bigger than his audience ', 'never forget kamala harri s has proven that she will destroy innocent people and good families to advance her agenda ', 'hey nancy where exactly is that salon ', 'dance my bitches dance ', 'they laughed when i said that i will drain the swamp they re not laughing now ', 'mainstream media joe biden s campaign ', 'chris wallace bias liberal', 'cry all you want he s doing exactly what i hired him for ', 'this is what stage 4 trump derangement syndrome looks like ', 'tonight there is a woman in america who has to live with the fact that the nfl will honor her rapist by wearing his name on their helmets', 'if you re wearing a mask but still eating out at restaurants you re not afraid of the virus you re afraid of your government ', 'if you ve never worn a mask for any one of the following common cold influenza diphtheria whooping cough pneumonia tuberculosis bronchitis pneumonia ask yourself why are you wearing one now really ', 'a liberals guide to labeling native american african american opressed competent hero scientist expert mostly peaceful female', 'did you know that every tire comes with a prebuilt gps chip so that you can be located in 5g networks if you don t want to be followed you have to cut off the little antenna that sticks out ', 'trump pence 2020 keeping america great ', 'presidential debate 2020', 'let the peasants do their own hair', 'birds turtles crabs humans', 'how to avoid getting shot by police 1 don t commit crime 2 keep hands visible 3 comply with commands 4 don t resist arrest 5 fight the charge in court not on the street ', 'you gotta wonder what did these bananas know about the clintons ', 'im not judging i m just showing you pictures of jacob blake', 'all socialism involves slavery that which fundamentally distinguishes the slave is that he labours under coercion to satisfy anothers desires herbert spender', 'the brain dead bunch', 'joe biden spotted heading to the dnc convention', 'trump scares me', ' come on man you know the thing just ask my wife joe the dog faced pony ', 'the president will once again be unreasonable and will refuse to sign our election reform bill how can this country progress so long as donald j trump is president he ll insist that voters 1 be a united states citizen 2 provide i d to prove citizenship 3 insure only one vote per person 4 insure vote counts are correct 5 insure the voter is a living person 6 states verify registratons are updated ', 'when there are no police most crimes will carry the death penalty', 'sorry i only grope women', 'brilliant trump puts himself on all postage stamps forcing democrats to push for abolishing usps the trump stamp greatest president ever', 'what they re thinking is she my wife or my sister i ll have to ask hillary how to make it look like an accident ', 'national attention vs not gonna mention what happened media you suddenly got so quiet', 'he was supposed to start kindergarten on monday instead he s being buried no protests for him no nba players kneeling in his memory no politicians screaming for justice just silence ', 'white lives matter justice for cannon shot in his head riding his bike by a black man just for being white ', 'mexican word of the day nissan when kamala harris got started in politics she burned her nissan the carpet', 'she ain t black ', 'but joe said he would pick a black woman', 'i am so excited that we get to watch kamala harris who swore into congress as an indian american now play the i m a black a woman card all the way until november fun times ahead ', 'i m joe biden and i forgot this message', 'i chose who ', 'brilliant picture proving what side facebook is really on turned their fact checkers off for this picture the fake picture on the left is being allowed to circulate on social media unchecked unblocked the real picture is of trump his daughter now someone tell me the mainstream media is not illegally controlled there s no hidden agenda with facebook etc fake', 'when you get ice cream for going a whole day without saying something stupid', 'democrat 2020 platform in a single photo', 'my husband is a hero thoughts on bill clinton my husband is a pedo', 'dear plexiglas thank you for protecting me from the cashier that just touched everything i m taking home ', 'her choices of great role models perverted misogynists rapists and men who drug before they rape nice ', 'joe biden s lifetime accomplishments ', 'on a scale of 1 to 1984 how free do you feel while wearing a muzzle in a grocery store while following arrows on the floor ', 'when your political agenda is more important than the people you represent you have become a danger to the nation this is today s democratic party ', 'maybe the nfl should put this up in every locker room the first african american to receive the medal of honor in the civil war was sgt william harvey carney who despite being shot in the face shoulders arms and legs refused to let the american flag touch the ground ', 'colin kaepernick and his evil white oppressors oh wait those are his parents ', 'looting an act performed in urban communities to honor a recently killed person that nobody knew but you tell people he was like a son proper looting etiquette dictates the underwear be fully visible at all times ', 'disney hey america look at who disney just hired to teach your kids about american history think about that next time you overpay to visit disneyland ', 'welcome back to another episode of things l d rather do than listen to nancy pelosi ', 'joe biden i regularly take cognitive tests the cognitive test ', 'not one politician has died from the virus lost their job or had their business looted y all know you re being played right ', 'democratic congresswoman alexandria ortiz cortez removing mask to blow covid particles bubbles into little girls face ', 'watch the media bury this story summer taylor a non binary blm activist was protesting on the freeway when she was fatally hit by this man summer taylor dawit kelete ', 'bill and i are not moving to ecuador get it done ', 'a july 4th message from joe merry christmas ', 'look son democrats destroying statues of racist democrats put there by democrats ', 'anyone know were the justice dept is holding ghislaine maxwell asking for a friend ', 'you can place your bets with me will it be a suicide b covid 19 c murder by inmate ', 'ghislaine maxwell arrested suicide hotline how can i help you i d like to place an order ', 'fbi hires top rated italian bodyguard hiluigi clintonelli to protect ghislaine maxwell ', 'when will we take down these monuments of slavery ', 'blocking a hwy doesn t impress me want to impress me y all go block a train track ', ' they closed your business they closed your church they closed your parks they closed your beaches they banned funerals they banned graduations they made you wear masks they banned dads in delivery rooms but they allow this you were played ', 'oh gosh someone spilled a truckload of assholes ', 'so i think we can all agree that switching from ass whoopings to time outs didn t have the outcome we had hoped for ', 'fear of riots is on the decline switch back to corona switch back to corona ', 'i planned to go fishing today but some racist put a noose in my tackle box ', 'wanna take statues down start with this useless motherfucker right here ', 'know what else they didnt find in wallaces garage a trophy ', 'it s a garage door rope and been proven that it s been there for years obviously it s a noose and put there because i m black ', 'and there i was in a nascar garage being the target of racists ', 'still more coherent than joe biden ', 'we re going to try the hillary campaign again but witha man this time and here s the twist he s completely incoherent joe 2020 ', 'brett has obviously had a few too many concussions comparing colin kaepernick to pat tillman ', 'the left if trump holds his tulsa rally thousands will die also the left ', 'instead of hands up don t shoot how about pull your pants up don t loot ', 'armed robbery in progress shots fired let me send an email to the mayor and city council members to see how i should respond hope they get back to me since its sunday afternoon ', 'the biden train ', 'how antifa sees themselves how real americans see antifa ', 'democrats clarify that black lives will only matter until november ', 'my name is chuck i am a worthless piece of shit that has milked america for my whole career i have not done anything for this country i am a true democrat ', 'this is fine this is fine this is fine nope covid ', 'i can t breath but don t worry i m white ', 'who is this aunt tiffa i wonder what she smells like ', 'the 54th massachusetts regiment memorial vandalized by black lives matter this week the 54th massachusetts regiment ', 'if we can do this then we can do this ', 'thousand protersters saying fuck the police hundreds call 911 when a truck shows up ironic ', 'a friendly reminder ferguson baltimore milwaukee charlotte in case y all forgot ', 'tony timpa killed by police brutality after the policeman had 13 minutes knee on his back above his lungs and they were joking that he passed after o fucks given by ppl george floyd killed by police brutality after the policeman had a knee on his neck for 8 minutes absolute mad protests two same situation two different reacts from american society ', 'when police departments are defunded caller help someone s breaking into my house 911 operator stay calm sir we are sending you our thoughts and prayers right now ', 'so we can all gather to do this but not to do this ', 'i went to a petting zoo yesterday that was an elementary school joe ', 'we seem to be moving steadily in the direction of a society where no one is responsible for what he himself did but we are all responsible for what somebody else did either in the present or in the past thomas sowell ', 'i could sit here all day and still be full of shit ', 'the devil bowed her head because she knew that she d been beat and she laid that golden pen on the ground at donald s feet donald said nancy just come on back if you ever want to try again i done told you once you drunk old bat i m still your president ', 'let me blow in your ear that s awesome thanks for the refill ', 'let me get this straight you know bill gates openly stated vaccines will be used to depopulate the world 10 15 that he ran pandemic drills in october called event 201 he already had a corona vaccine patent and you re still going to take his vaccine are you fucking insane ', 'in an effort to level the playing field barron trump will debate joe biden ', 'sorry but i don t listen to anti gun lectures from people who think it s ok to kill a baby ', 'so what did you learn at home during the pandemic i m a boy i m a girl nuke goddam china ', 'i and i alone control your worlds climate now shut the fuck up or i ll fry your asses ', 'on my way back to the white house mr trump needs me america needs me ', 'when the holy spirit cranks the pastor up and he gets real specific about your situation ', 'democrats love saying orange man so much they nominated a vegetable ', 'if we wipe out the coronavirus when the warm weather comes we can tell the liberals that global warming killed it and watch their heads explode ', 'when the left finds out sunshine kills the china virus ', 'how you think you look protesting the lockdowns how you actually look protesting the lockdowns help help i m being repressed ', 'mexican word of the day biden help this gringo is biden my ear ', 'everything is going as planned ', 'how to kill the coronovirus hey hillary i hear the coronavirus is going to testify against you ', 'remember no matter how bad things get at least you re not quarantined with hillary ', 'when there have been 0 mass shootings during quarantine when guns and ammo are being bought in mass would you just look at that', 'impeach the democrats keep america great', 'if nonessential was a human', 'the face you make when realizing covid 19 dies at 80 degrees and global warming can save us', 'infected for 9 days been in contact with 42 people asymptomatic feeling fine infected for 35 minutes about to get super sick miss two weeks of work a truck payment dating a nurse mom has cancer has asthma asymptomatic lucky for you could be bad luck for everyone else ', 'normal people conspiracy theorists', 'when i walk into a southern grocery store with my mask on', 'when i hear someone basing their trust in a vaccine on which politicians approve it without even looking at what scientists say ', 'david skipped the flu shot he got sick and recovered within a week his elderly grandmother was not so lucky vaccines it isn t always about you ', 'before you let that political advertisment outrage you try to remember the last time a political ad told you anything objectively ', 'anti maskers you ll never take our freedom the rest of society you re just going to the store mate put yer fuckin mask on ', 'this is an antidepressant this is shit depression is a serious illness that kills over 800 000 people every year its causes and treatments are complicated and nuanced it is not something that can be treated flippantly with a day in the forest ', 'homeopathy is fake medicine that by definition has no active ingredients the so called doctors who prescribe it are either incompetent or frauds they are giving fake medicine to sick people and belong in jail ', 'before we get started sir is your blood type liberal conservative or independent yes making medical decisions based on politics is as stupid as this sounds ', 'maybe if we renamed diseases after anti vaccine activists less children would have to suffer like this child with jim carrey s disease chicken pox ', 'i have a conspiracy blog that exposes the way big corporations control the world by propaganda your blog is hosted on amazon registered by goldaddy and mostly found via google tell me again how this propaganda thing works ', 'l ll never know measles chicken pox polio or whooping cough thanks for having me vaccinated mom i love you', 'mom can t i see a doctor no honey i m sure gonzosk8r69 knows what s best for you ', 'common name asian giant hornet name the media uses to scare you into clicking links murder hornet', 'when your anti vaccine friend is upset that you called them on their bullshit ', 'if anti lockdown protest logic were applied to other areas of life ok guys we ve slowed to a safe falling speed so we clearly don t need these parachutes anymore ', 'if you truly believe i can hear your thoughts and prayers wherever you are then it doesn t make a lot of sense to crowd together in a church during a pandemic does it ', 'this is your child this is your child on vaccines any questions ', 'if you think your body has energy fields it means you don t actually understand what energy is ', 'the reason i don t eat plant based meats is because i want to support our farmers sure but aren t you ignoring the plight of hard working people in the soybean mines ', 'the radiation emitted from this lamp is far more energetic than 5g signals neither are harmful to your health except when you use them to read woo on the internet ', '50 000 people die from influenza and most people don t get vaccinated a few cases of ebola sars or corona virus show up and everyone loses their minds ', 'number of confirmed injuries due to strangers tampering with halloween candy since 1970 none number of confirmed injuries due to meteorites since 1970 1100 ', 'still waiting for peer reviewed evidence of eating gmo foods harming human health ', 'nathan rothschild part of a family who never financed both sides of any war doesn t own any central banks are accused by conspiracy theorists of having more money than actually exists ', 'the annual conference of scientists who have proven that gmo foods are harmful seems just as busy as last year s ', ' we know that the increase in atmospheric co2 comes from fossil fuels by examining isotopes we know that an increase in co2 means that more heat is trapped in the atmosphere adding more co2 to the system will result in an increase in temperature but some people at the climate protest were littering ', 'just a heads up most quotes you see from me being passed around the internet aren t actually mine morgan freeman ', 'where did the ancient concept of qi and meridians that your acupuncture practitioner speaks of originate from this french author in 1939 nothing ancient or chinese about it ', 'yes i m homeopathic why do you ask i d like to see a real medical doctor instead if you don t mind ', 'if you criticize others for ignoring hard scientific data confirming anthropogenic global warming but ignore hard scientific data that shows gmo foods are safe and organic food has no nutritional advantage you re doing science wrong ', 'this site is bound to be honest and unbiased it has the word truth right in the url ', ' i m really worried about getting cancer from those wind turbines well they blow the chemtrails away so i think it s worth the risk ', 'i don t get it my parents refuse to vaccinate me because they say the aluminium in vaccines is poison then they go and feed me food that contains aluminium all day ', 'naturopathy for those who want to look like a real doctor but cant be bothered with all that pesky science ', 'most children undergoing cancer treatment cannot be vaccinated their lives are in danger from unvaccinated people vaccines it isn t always about you ', 'cancer cures are suppressed because there s more money to be made in treating than curing you re trying to tell me tobacco companies wouldn t page huge money for a lung cancer cure ', ' spreading the chemtrails is actually quite easy getting them right to the edge of the earth without flying off into space is the difficult part ', 'breaking news university of google alumni left reeling as dunning kruger syndrome spreads unchecked through their ranks ', 'in case you fell for it israeli scientists have not found a cure for all cancers it was just another case of bad science reporting by a credulous media ', 'large studies have found no correlation between glyphosate use among farmers and cancer rates none zip nada zilch ', 'while there s no scientific consensus that acupuncture actually works you can reasonably argue that it can have a placebo effect on humans animals however do not respond to placebos so all veterinary acupuncturists are doing is stabbing your pets for money animal cruelty plain and simple ', 'the only thing essential oils are essential for is the seller s income aromatherapy has no proven medical benefits ', 'claims big pharma won t sell natural medicines because they can t make a profit off what they can t patent spends 120 a month on water ', ' i can t believe how cold it is lately so much for global warming you mean the sea levels are falling and hundreds of thousands of square kilometres of polar ice has returned that s fantastic news ', 'turkey does in fact contain l tryptophan which can induce drowsiness but no more than beef chicken or other common meats so the drowsiness is more likely because you ate like a pig had some wine and then ate some more ', 'try to think of all the natural things that can harm or kill you then ask yourself why that word sways your choice of food ', 'could those of you saying that someone losing a twitter account is akin to life under the nazis kindly stfu ', 'diphtheria polio smallpox that s the problem with you pro vaccine people you keep bringing up diseases that almost nobody hears about anymore ', 'marty i m going back in time again why is something wrong with my parents no l just wanted to live in a time when vaccines being a good thing and the earth being a globe wasn t something people actually debated ', 'calls for a ban on glyphosate based on a mistaken belief that it may be carcinogenic keeps drinking wine which is carcinogenic ', ' those who believe without reason cannot be convinced by reason james randi ', 'we know the moon landings were not faked because that s how we discovered the earth was flat ', 'today we salute the 400 000 people involved in faking six moon landings for keeping their mouths shut for 49 years ', 'jake believes he s woke he is suspicious of anything said by the government corporations or any authority yet he believes random uncited memes circulating on facebook without question jake ain t woke ', 'claim acupuncture is a form of chinese medicine that is thousands of years old however the technology for making the needles is only a few hundred years old ', 'had a brain injury and forgot everything he learned in medical school successful naturopath ', 'when someone ignores your peer reviewed citations and tells you to do ur research ', ' if chemtrails aren t real explain why they appear to turn on and off all the time the same reason why you see your breath on a cold day but not a hot day dummy ', 'aside from the vitamin seller this is the main beneficiary when you megadose vitamins ', ' so why are we marching against monsanto and not all the other companies who make the same products uh just chant the slogans and don t ask questions ', 'i m going to strike a blow at monsanto expose the rothschilds and warn everyone about big pharma as long as i don t have to get off the sofa ', 'while well fed westerners campaign against crops genetically modified to be higher yielding and drought resistant those with no voice continue to die in drought induced famines ', ' i can t believe how much positive feedback i m getting from other anti vaccine activists on facebook i m glad you re getting some attention dad but why am i the one who has to get sick ', 'ate 5000 calories per day for a month thinks the restaurant is the problem ', 'ok explain this to me again exactly how does breaking blood vessels and causing clots and bruising enhance circulation ', 'for those times when you just can t make it to your reiki session but you wanted the same results ', 'researchers have developed a type of rice to combat vitamin a deficiencies in poor countries that cause widespread blindness and over 600 000 childhood deaths annually the well fed people at greenpeace oppose this what kind of people are they ', 'when are you anti vaccine nuts going to stop making the autism claims it was proven wrong years ago as soon as you science nerds stop making the same tired old dihydrogen monoxide jokes over and over again ', 'hunter taking press questions ', 'i take a shit every morning at 8 am that s good so what s the problem i wake up at 9 am ', 'sen mazie hirono d hawaii the dumbest person in the u s capitol questions judge amy coney barrett the smartest person during confirmation hearings this week normally the dumbest designation goes to rep maxine waters d calif but ms waters was not present in the building ', ' obama kicked me out trump invited me back ', 'i am getting very concerned this man hasn t called me yet to tell me how to vote ', 'biden for president ', 'magnification reveals how low democrats will go to smear the opposition biden harris ', 'let s take a stroll down memory lane shall we ', 'facetime thanksgiving is better than tummy time christmas ', ' vaccines are just a way for doctors big pharma to make money said the ignorant internet doctor who thinks this is free ', 'you ain t black you ain t president ', 'in order to stay out of facebook jail i will be posting memes in code is a ', 'just like bernie i m all for making the minimum age 15 wage joe the minimum wage you idiot ', 'sniff dog ', 'what now boss i m not your boss this time joe that s kamala now ', 'hunter biden celebrating his dad s victory peanutbutter and crack sandwich ', 'pornhub interracial couple fuck entire nation ', 'trump rally can you spot the difference biden rally ', 'telling you right now my name better not be on your dumb ass kids computer ', 'during halloween some states require child sex offenders put signs up stay informed biden for president ', 'meet the biden boys sniff snort ', 'trump kids campaigning for dad hunter biden ', 'joe biden presents the poor boys ', 'president trump s rallies should feature a wall of mirrors behind him to force the media to show the enormous enthusiastic crowd in front of him ', 'i d crawl blindfolded and naked over a mile of broken glass slathered with germs to vote for trump and every other republican on the ballot in 2020 ', 'asked what the d c stands for in washington d c rep alexandria ocasio cortez thought for a moment and replied confidently dot com ', 'communists around the globe are loving these 2 ', 'there is no voter fraud we won fair and square then you should have nothing to worry about ', 'we decide the election not the media ', 'iraq has better election security than pennsylvania ', 'i can t believe the hispanics cost us florida well you were peddling socialism to cubans so ', 'if you think for one second i m gonna surrender my guns to a government that doesn t think twice about slaughtering a helpless baby you ve absolutely lost your damn mind ', 'yea we gonna recount the georgia ballots ', 'media projections are not election results ', 'juanita brazile ', 'calm down little trump haters let the supreme court do its job ', 'well hi there kamala it s been a little while ', 'i have indian blood in me imahoe isn t a tribe ', 'i got your behind america ', 'i m watching newsmax and i haven t seen either of these assholes once ', '000 you almost had it ', 'republicans america democrats china ', 'somewhere out there there s a liberal looking at my page just like this everybody wave at the snowflakes ', 'ten minutes into the campus activist s lecture about the gender spectrum murray is slowly beginning to realize why the church used to burn witches ', 'it s okay joe i was president for a few days too ', 'fox news channel oct 7 1996 nov 4 2020 ', ' and i said if you don t find more votes we re not gonna win this election well son of a bitch we found more votes ', 'have you accepted communism as your lord and savior ', 'fake news bestseller the art of the steal joe biden', 'here to collect my reparations check', 'that s a nice business you got there be a shame if someone closed it', 'you didn t lock any of us up before the election and you thought it would be even remotely fair ', 'fox news is going left fox news sucks walk away', '4 634 people died of covid in china total we re at 177 000 and climbing don t call it the china virus this sh t is the trump mumps ', 'organized religion because nothing feeds the hungry helps the poor or takes care of the sick like spending 1 1 million dollars to build a 198 foot steel cross ', 'long after this moron is dead history will remember the cowards who kept quiet and let this go on', 'trump should move the gop convention to the kremlin that way all the party can attend get the kind of tv news they like ', 'what s more likely putin wanted trump to win because he liked him or because he knew trump was weak and stupid ', 'at this point shouldn t his rallies be considered a farewell tour ', 'we owned the libs hell yeah we did ', 'he acted faster against the imaginary threat of caravans than the actual threat of coronavirus ', 'after trump is gone one of the things i m going to remember is the cowardice of people who went along ', 'did you hear trump in today s briefing when he offered his heartfelt sympathy for the families who ve lost loved ones to coronavirus yeah me neither', 'don t listen to this completely unstable moron he only cares about and his imminent loss in 2020 listen to me only not the moron next to me', 'president s day special white russian cheetos', 'presidents day sale everyone must go', 'when you ask where all the money went', 'let s have illegal immigrants hunt down sex offenders for a chance at citizenship we ll call it aliens vs predators ', 'if 2020 was a prime minister', 'police should investigate covid fraud not persecute those who do their job for them', 'stop looking at guns you already have 20 why cant you just look at porn like a normal man', 'the problem is not that trudeau is an incompetent entitled lying virtue signaling backstabbing fake idiot who has no business leading a country the problem is his supporters don t care ', 'if you go to a party you will go to jail because coronavirus if you are in jail we will let you out because coronavirus', ' joe biden fuck you', 'who built the cages joe ', 'new walmart greeter bless his heart welcome to target', 'hunter biden says white lines matter', 'if you like subpoena coladas and getting caught in ukrain when your dad s into children and you are into cocain', 'chinese businessman arrested for operating illegal casino in 9 million mansion in toronto wei met with justin twice and gave 1 million to the trudeau foundation', 'anti vaxxers self perception reality', 'human 1350g chimpanzee 400g orangutan 400g i ve done my own research ', 'antivax antivax fucking idiot', 'i saw you share anti vax memes you are getting a science textbook this year', 'a microchipping syringe a vaccine syringe any questions ', 'are you taking me to the hospital no ma am you need top medical experts we re taking you to the comments section ', 'maybe court decisions just isn t your game know let s have a spelling contest', 'maybe elections aren t your game trump cultists i know let s have a spelling contest ', 'taiwan population 23 78 million cases 553 deaths 7 florida population 21 48 million cases 795 000 deaths 16 647 nearly identical population opposite response ', 'cnn projection donald trump wins the state of denial', 'if democrats had rigged the election these 4 morons wouldn t have won reelection ', 'just remember when we dump trump they all go too ', 'the moral of the story is he lied to you for months and encouraged you to live recklessly during a pandemic and when it got to him he received every top tier treatment and medication to ensure his survival while your friends and family died alone remember that on nov 3rd ', 'trumpkin orange on the outside hollow on the inside and should be thrown out in november', 'the face you make when you realize just comply and don t resist applies to you too', 'let me repeat this for those that didn t hear me this is the first time ever that the justice department has defended a rape case instead of prosecuting it ', 'trump is gonna fix the shitty job the current president is doing', 'trump didn t make america racist he made the racists feel comfortable enough to show their faces in public ', 'for all those posting pictures of kyle rittenhouse cleaning graffiti here s a picture of ted bundy doing the dishes the ability to clean doesn t exclude someone from being a murderer ', 'dr fauci have a fan implanted to your head to blow the covid 19 virus away from your face ', ' you won t take my chip with a patent number 060606 how dare you ', 'rep jerry nadler in car accident it wasn t me', 'aoc after getting called a bitch the attempt on my life has left me scarred and deformed', 'i would have never voted for me ', 'how to kill the coronovirus hey hillary i hear the coronavirus is going to testify against you ', 'look when i m in the waffle house i m going to white house honey white house', 'i support mlb it s blm you idiot', 'pelosi endorses biden he is a leader who is the personification of hope and courage values authenticity and integrity thank you i said no licking ', 'if you trust someone who has 500 000 shares with monsanto injured thousands of people with vaccines plans to block out the sun advocated for microchipping sponsored marina abramovic you re a special kind of stupid']\n",
            "[[[0]], [[1]], [[2], [3], [4], [5]], [[6], [2], [3], [4], [5]], [[1]], [[7], [6], [8], [4]], [[2], [3], [9], [5]], [[2], [3], [5]], [[2], [3], [10]], [[6], [11], [2], [3]], [[7], [2], [4], [5]], [[6], [2], [3]], [[12]], [[2], [3]], [[2], [4]], [[8], [11], [2], [12], [3], [5]], [[7], [2], [4]], [[8], [2], [5]], [[13], [2], [3], [5]], [[2]], [[10]], [[2], [12], [3], [14], [5]], [[1]], [[2], [4]], [[2], [3], [5], [15]], [[1]], [[2], [3]], [[8], [3], [5]], [[1]], [[7], [6], [8], [2]], [[6]], [[2]], [[6], [11], [5]], [[7], [8], [16], [2], [3]], [[7], [0], [4]], [[16], [4], [5]], [[1]], [[7], [0], [8], [3], [9], [4], [5], [17]], [[2], [3], [15]], [[3]], [[3]], [[5]], [[6], [5]], [[8], [16], [2], [12], [5]], [[16], [2], [3], [9], [4], [5]], [[11], [2], [3], [5]], [[2], [4]], [[2], [5]], [[2], [3], [9], [5]], [[8], [5]], [[9]], [[18]], [[2], [3]], [[7], [6], [11], [2]], [[4], [5]], [[2]], [[19], [0], [2], [3]], [[2], [3], [5]], [[6], [5], [17]], [[2], [12], [14]], [[3]], [[5]], [[2], [3]], [[8], [2]], [[1]], [[8]], [[19], [8], [5]], [[3], [5], [17]], [[2], [3]], [[2], [3]], [[2], [3]], [[2], [3]], [[7], [16], [2], [3], [5], [15]], [[8]], [[1]], [[1]], [[1]], [[17]], [[2]], [[16], [2], [3]], [[2], [3]], [[0], [13]], [[8], [2], [12], [4], [5]], [[13], [2]], [[8], [5]], [[7], [2], [3], [5]], [[2], [10], [4]], [[1]], [[19], [6], [2], [3], [17]], [[13], [8], [3]], [[2], [4]], [[7], [16]], [[3]], [[16], [2], [3], [4]], [[7], [2], [3]], [[2]], [[7], [2], [3], [5]], [[2], [3]], [[2]], [[0]], [[7], [16], [11], [2], [3]], [[6], [8], [5], [17]], [[1]], [[2], [3]], [[4], [5]], [[20], [8], [2]], [[2]], [[2], [3]], [[7], [2]], [[2], [3], [5], [15]], [[1]], [[2], [3]], [[1]], [[3]], [[7], [17]], [[16], [2], [4], [5]], [[6], [2], [5]], [[0]], [[2], [3]], [[3]], [[7], [2]], [[1]], [[8], [2], [12]], [[3]], [[7], [0], [2], [3]], [[1]], [[8], [2], [15]], [[8]], [[1]], [[8], [5], [17]], [[1]], [[8], [2], [5]], [[1]], [[2], [3]], [[7], [2], [5]], [[15]], [[1]], [[13], [2]], [[2], [3], [5]], [[1]], [[1]], [[2]], [[2]], [[2], [3], [5]], [[1]], [[5], [17]], [[6], [2]], [[2], [12], [3], [4]], [[16], [4]], [[7], [0], [2], [3]], [[2], [3], [15]], [[1]], [[2], [3]], [[2], [3]], [[1]], [[16], [11], [2], [3], [5]], [[0], [8]], [[8], [2], [3], [4], [5]], [[11]], [[1]], [[2]], [[2], [3], [5]], [[2], [3], [15]], [[2], [3]], [[4], [5]], [[1]], [[13]], [[2]], [[8], [2]], [[5]], [[2]], [[7], [5]], [[2], [3]], [[2], [5]], [[1]], [[8], [3]], [[6], [11], [5]], [[7], [6], [12]], [[0], [8]], [[5]], [[13]], [[2], [3]], [[2], [3], [5]], [[3]], [[1]], [[1]], [[13]], [[1]], [[1]], [[1]], [[1]], [[3], [5]], [[2], [3]], [[1]], [[2]], [[7], [2], [3], [4]], [[1]], [[8], [11], [3]], [[19], [2], [3]], [[2], [12], [3]], [[7], [2]], [[13], [5]], [[1]], [[13]], [[6], [2], [5]], [[16]], [[2]], [[1]], [[8], [11], [2], [17]], [[8], [2]], [[2], [12], [5]], [[1]], [[2]], [[1]], [[1]], [[3]], [[11], [2]], [[1]], [[13]], [[2]], [[8], [11], [3]], [[1]], [[8]], [[3]], [[2]], [[2]], [[1]], [[13]], [[2], [3]], [[11], [5]], [[4]], [[2], [3], [5]], [[1]], [[2], [3]], [[2]], [[1]], [[2]], [[5]], [[1]], [[5]], [[1]], [[1]], [[13]], [[2], [5]], [[8], [3]], [[13]], [[3]], [[15]], [[16], [11]], [[1]], [[15]], [[1]], [[13], [15]], [[1]], [[13]], [[19], [16], [3]], [[1]], [[8], [11], [2]], [[11], [3]], [[2], [3]], [[1]], [[11], [3]], [[16], [4]], [[8]], [[1]], [[19], [4]], [[8], [11], [3], [5]], [[4], [5]], [[8], [2]], [[2], [3]], [[2]], [[6], [3], [5]], [[1]], [[1]], [[2], [5]], [[11]], [[11], [5]], [[13], [15]], [[5]], [[1]], [[1]], [[19], [7], [2], [3]], [[3], [5]], [[2]], [[2], [3], [15]], [[7]], [[3]], [[6], [2]], [[11], [2], [3], [5]], [[0]], [[7], [13], [2], [3]], [[11], [5]], [[10]], [[2]], [[2], [3], [5], [15]], [[1]], [[16], [5]], [[2], [5]], [[1]], [[5], [15]], [[0], [2], [3], [5]], [[13]], [[1]], [[2], [3], [5], [15]], [[6], [13], [2], [12], [5]], [[2], [5]], [[1]], [[13], [2]], [[2], [3]], [[2]], [[2], [15]], [[1]], [[7], [8], [2], [3]], [[1]], [[2], [12], [15]], [[5]], [[1]], [[1]], [[5]], [[7], [16], [2], [3], [5]], [[2]], [[2], [3]], [[2], [3]], [[2], [17]], [[2], [5], [17]], [[1]], [[13], [2]], [[7], [2]], [[6]], [[7], [6]], [[16], [2], [9], [4]], [[2], [5]], [[2], [3]], [[2]], [[1]], [[1]], [[6], [8], [16], [2], [3]], [[7], [8], [2]], [[7], [2], [3], [15]], [[7], [2], [5]], [[13], [15]], [[16], [2], [3]], [[2], [3], [15]], [[2], [3], [5]], [[7], [10]], [[2], [15]], [[13]], [[2], [3], [5]], [[2]], [[6], [2], [3]], [[19]], [[19], [2], [5]], [[2]], [[1]], [[2], [3]], [[2], [5]], [[1]], [[2], [5]], [[5]], [[5]], [[2], [3], [9], [5]], [[2]], [[2], [3], [5]], [[13], [2], [3], [4]], [[11], [2], [3]], [[2], [3], [4], [5]], [[1]], [[13], [2], [12], [15]], [[5]], [[1]], [[2], [5]], [[1]], [[2]], [[2]], [[2], [5]], [[2]], [[8], [2], [5]], [[2]], [[2], [3], [5], [15]], [[16], [2], [5]], [[1]], [[0], [11], [2], [5]], [[1]], [[2], [3], [5]], [[8], [11]], [[4], [5]], [[8]], [[5]], [[8]], [[11], [2]], [[8], [5]], [[2], [3], [5]], [[1]], [[2], [3]], [[4]], [[1]], [[2], [3]], [[2], [17]], [[3], [5]], [[2], [3], [5]], [[6], [2]], [[13]], [[2]], [[7]], [[16], [4]], [[1]], [[2], [3]], [[1]], [[2]], [[13]], [[1]], [[19], [2], [9]], [[3]], [[1]], [[2]], [[2], [3]], [[11]], [[7], [2]], [[2]], [[8], [11], [3], [4], [5]], [[0], [5]], [[13]], [[2], [15]], [[6], [2], [3], [4]], [[2], [5]], [[1]], [[3]], [[5]], [[5]], [[1]], [[13], [2], [3], [5], [17]], [[2]], [[1]], [[2], [3], [5]], [[1]], [[2], [3], [5]], [[1]], [[7], [2]], [[16], [2], [3], [5]], [[16], [2], [5]], [[2], [3], [5]], [[2], [5]], [[5]], [[5]], [[1]], [[13], [2]], [[2], [3], [5]], [[2], [5]], [[1]], [[5]], [[2], [3], [5]], [[1]], [[2]], [[1]], [[3], [5]], [[2], [3]], [[1]], [[2], [10], [15]], [[8], [2]], [[20], [2], [17]], [[2]], [[2], [3]], [[2], [3]], [[5]], [[2]], [[2], [3]], [[1]], [[3], [5]], [[5]], [[2]], [[2], [5]], [[2]], [[1]], [[16], [3]], [[12], [5]], [[2], [3], [5]], [[10]], [[1]], [[1]], [[2]], [[1]], [[2], [15]], [[1]], [[2], [15]], [[2]], [[1]], [[5]], [[19]], [[2]], [[2], [3], [5], [17]], [[2]], [[7], [13], [2], [12], [5]], [[5]], [[2], [12], [3], [14], [15]], [[2], [3], [4]], [[7], [0], [8], [2]], [[1]], [[2]], [[3], [5]], [[2], [5]], [[2], [3]], [[2]], [[2], [3]], [[1]], [[2], [5]], [[5]], [[2]], [[16], [4], [5]], [[1]], [[2]], [[2]], [[1]], [[1]], [[1]], [[7], [4]], [[13], [2]], [[2], [4], [5]], [[7], [2]], [[0], [2], [3], [5]], [[2]], [[13], [3], [5]], [[13], [2], [3], [15]], [[8], [2]], [[5]], [[2], [3], [5]], [[2], [3], [5]], [[13], [12], [3]], [[2], [5], [15]], [[17]], [[5]], [[2], [3], [15]], [[2]], [[8], [2], [15]], [[1]], [[13], [2]], [[13], [2]], [[2]], [[5]], [[19]], [[13]], [[3], [5]], [[2], [3], [17], [15]], [[2], [3]], [[2]], [[13], [2], [15]], [[2], [3], [5]], [[2], [4]], [[6], [13], [2], [12], [3]], [[14]], [[2], [3], [4], [5]], [[2], [3]], [[10]], [[2], [5]], [[5]], [[15]], [[2], [12], [3]], [[2]], [[13], [2], [3]], [[2], [17]], [[1]], [[1]], [[7], [2], [3], [15]], [[19]], [[2]], [[13], [2]], [[13], [2], [3], [15]], [[13]], [[3]], [[1]], [[13], [2], [3]], [[3]], [[0], [17], [15]], [[2], [5]], [[2], [3], [15]], [[1]], [[1]], [[13], [2]], [[1]], [[2], [3], [5]], [[2], [3]], [[1]], [[2]], [[8], [11], [2], [3], [5]], [[2]], [[2]], [[4]], [[2], [5]], [[1]], [[3]], [[13], [2], [3], [5]], [[1]], [[2], [3]], [[2], [3], [5]], [[1]], [[3], [5]], [[2], [5]], [[2]], [[1]], [[2], [3]], [[2], [4]], [[3], [5]], [[1]], [[2], [3]], [[11], [2], [3]], [[11], [2]], [[5]], [[2], [9]], [[2]], [[1]], [[5]], [[1]], [[2], [3], [5]], [[1]], [[1]], [[1]], [[2], [3]], [[1]], [[2], [5]], [[1]], [[2], [3]], [[1]], [[1]], [[2], [3]], [[2], [5]], [[5]], [[5]], [[2], [3]], [[2], [3]], [[2], [3], [5]], [[1]], [[2], [3]], [[2]], [[2], [5]], [[2], [3], [5]], [[2], [5]], [[2], [3]], [[5]], [[2], [3], [5]], [[3], [5]], [[2]], [[2], [3], [5]], [[2], [5]], [[2], [3], [5]], [[2], [3], [5]], [[3]], [[1]], [[1]], [[2], [3]], [[1]], [[2], [5]], [[3]], [[2], [3], [5]], [[2]], [[2], [5]], [[1]], [[2]], [[2], [5]], [[2], [5]], [[2], [5]], [[1]], [[1]], [[2], [3]], [[3]], [[1]], [[1]], [[1]], [[2], [3]], [[5]], [[3], [5]], [[2], [3], [5]], [[2]], [[2], [5]], [[3], [5]], [[2]], [[2], [5]], [[2], [3]], [[2]], [[2], [3]], [[1]], [[1]], [[1]], [[2], [3], [5]], [[1]], [[5]], [[1]], [[2], [3]], [[2]], [[2], [3], [5]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(cleaned_sentences))\n",
        "\n",
        "# Including the <s> and </s> tokens, the max sentence length = 82\n",
        "# There are in total 688 sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-I1x8POxRhZ",
        "outputId": "2933b0fc-e572-4a3b-ab46-6905a89be857"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(cleaned_sentences,padding=True,truncation=True,return_tensors='tf')\n",
        "print(inputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnX9puhNwGN6",
        "outputId": "c2a36dad-9de0-4d6b-f324-c3f9a12f519d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': <tf.Tensor: shape=(688, 82), dtype=int32, numpy=\n",
            "array([[  101,  2045,  2024, ...,     0,     0,     0],\n",
            "       [  101,  2023,  2003, ...,     0,     0,     0],\n",
            "       [  101,  2061, 15941, ...,     0,     0,     0],\n",
            "       ...,\n",
            "       [  101,  1045,  2490, ...,     0,     0,     0],\n",
            "       [  101, 21877, 10483, ...,     0,     0,     0],\n",
            "       [  101,  2065,  2017, ...,     0,     0,     0]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(688, 82), dtype=int32, numpy=\n",
            "array([[0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0],\n",
            "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(688, 82), dtype=int32, numpy=\n",
            "array([[1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***BERT is a encoder only transformer, now we feed our tokenized sentences to BERT and use the encoder hidden state and input it to the decoder.***"
      ],
      "metadata": {
        "id": "Bb4VPJTcyF2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = model(inputs)\n",
        "print(outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Po7n9pbEyTEB",
        "outputId": "f8e2ec8c-0d93-47b4-889a-d10072492c9f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<tf.Tensor: shape=(688, 82, 768), dtype=float32, numpy=\n",
            "array([[[-3.78582835e-01,  1.74619019e-01, -1.12571716e-01, ...,\n",
            "         -2.18954861e-01,  3.68135542e-01,  4.78350252e-01],\n",
            "        [ 2.34085694e-03,  4.21275973e-01, -4.79490161e-01, ...,\n",
            "         -2.94536442e-01,  4.60918993e-01, -4.60693613e-02],\n",
            "        [ 2.39521578e-01,  1.24723732e-01, -1.03663921e-01, ...,\n",
            "         -4.30854976e-01, -1.71649545e-01,  1.24428391e-01],\n",
            "        ...,\n",
            "        [-2.68685341e-01, -4.94127452e-01,  8.20762515e-02, ...,\n",
            "         -8.45117792e-02, -5.51631078e-02,  3.67361039e-01],\n",
            "        [ 1.36672154e-01,  1.34365320e-01,  1.98123172e-01, ...,\n",
            "         -1.13645181e-01,  1.92668021e-01,  2.49377653e-01],\n",
            "        [-7.82009587e-03, -2.32678190e-01,  2.25917488e-01, ...,\n",
            "         -7.60363415e-02, -9.11264867e-02,  2.47277632e-01]],\n",
            "\n",
            "       [[ 1.08501874e-01,  2.37600267e-01, -1.83187962e-01, ...,\n",
            "         -1.37840182e-01,  1.87398762e-01,  3.04920703e-01],\n",
            "        [-6.25662267e-01, -6.89340681e-02,  9.88295451e-02, ...,\n",
            "         -7.34609902e-01,  3.31449687e-01,  3.64555806e-01],\n",
            "        [-2.31332228e-01, -3.88448834e-01, -3.00122127e-02, ...,\n",
            "         -1.22279197e-01,  1.67381465e-01,  5.89458406e-01],\n",
            "        ...,\n",
            "        [-2.62769312e-03, -1.98458582e-01,  2.11904347e-01, ...,\n",
            "          2.00765535e-01,  5.59190586e-02,  8.28198120e-02],\n",
            "        [ 2.48983279e-01, -5.75817600e-02,  3.03500652e-01, ...,\n",
            "         -1.14642978e-01,  4.03952040e-02,  3.21210891e-01],\n",
            "        [-2.28404067e-02, -1.48079515e-01,  1.52231097e-01, ...,\n",
            "          1.53486848e-01,  1.60895318e-01,  2.29444832e-01]],\n",
            "\n",
            "       [[-1.46617681e-01,  1.18402235e-01, -3.66088226e-02, ...,\n",
            "         -6.15227997e-01,  5.32038331e-01,  1.38878211e-01],\n",
            "        [ 7.66133964e-01, -2.19188169e-01,  4.34344709e-01, ...,\n",
            "         -3.21478546e-01,  8.50872040e-01, -2.43316293e-02],\n",
            "        [ 1.41346133e+00,  4.13181037e-01,  5.82969666e-01, ...,\n",
            "         -3.94165397e-01,  1.27500072e-01,  6.69024885e-02],\n",
            "        ...,\n",
            "        [ 5.67399971e-02,  3.42332795e-02,  1.17819831e-02, ...,\n",
            "          1.04410574e-02,  3.68962377e-01, -4.11268026e-01],\n",
            "        [-1.98859647e-01, -2.07788542e-01,  7.08514452e-01, ...,\n",
            "          4.47959393e-01, -1.48531556e-01,  3.61854404e-01],\n",
            "        [ 1.42307401e-01, -1.90321073e-01,  1.85892910e-01, ...,\n",
            "          1.08002901e-01,  3.89414430e-01, -1.49392173e-01]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[-3.20786200e-02,  4.62753177e-01, -2.00911343e-01, ...,\n",
            "         -5.80291629e-01,  5.98000944e-01,  2.60618985e-01],\n",
            "        [ 4.39363539e-01,  1.27819434e-01, -4.54832241e-02, ...,\n",
            "         -3.73978376e-01,  7.01838732e-01,  5.98606527e-01],\n",
            "        [ 1.77918360e-01,  7.88870752e-01,  6.03465915e-01, ...,\n",
            "         -4.41004276e-01,  1.92757443e-01,  4.35799986e-01],\n",
            "        ...,\n",
            "        [ 8.33657235e-02,  4.66032401e-02, -3.73599052e-01, ...,\n",
            "          4.59649980e-01,  4.52751011e-01, -2.02869788e-01],\n",
            "        [ 2.58398741e-01, -2.22630695e-01,  2.69553773e-02, ...,\n",
            "          3.50185066e-01,  5.02768159e-01, -2.91966319e-01],\n",
            "        [ 3.43056232e-01,  2.22888470e-01,  5.13534844e-01, ...,\n",
            "         -1.23741031e-01,  2.97344089e-01,  1.63011372e-01]],\n",
            "\n",
            "       [[-3.47334594e-01,  1.00955471e-01, -6.93801790e-02, ...,\n",
            "         -5.13712347e-01,  4.65888321e-01,  2.04762205e-01],\n",
            "        [-5.08437932e-01,  7.68448487e-02, -2.57315785e-01, ...,\n",
            "          4.79809552e-01,  4.74294484e-01,  2.92086095e-01],\n",
            "        [ 4.86157060e-01,  1.50017962e-01,  7.82080173e-01, ...,\n",
            "          7.98405111e-01, -4.47667569e-01,  3.57573867e-01],\n",
            "        ...,\n",
            "        [ 3.20972949e-01,  4.87240613e-01,  4.54971045e-02, ...,\n",
            "         -2.72048056e-01, -1.16567612e-02, -2.63855994e-01],\n",
            "        [ 3.74332011e-01,  2.29956478e-01,  1.17327027e-01, ...,\n",
            "         -1.96030229e-01, -1.09209999e-01, -9.42972451e-02],\n",
            "        [ 1.26139030e-01,  2.70024478e-01,  2.08079755e-01, ...,\n",
            "         -5.23367785e-02, -8.91373679e-02, -1.02782294e-01]],\n",
            "\n",
            "       [[ 1.90438926e-01,  4.29024175e-02, -1.10146858e-01, ...,\n",
            "         -4.58532184e-01,  3.11488181e-01,  7.14923680e-01],\n",
            "        [-5.03453240e-02,  7.95013070e-01,  2.54925907e-01, ...,\n",
            "         -8.25760245e-01, -1.64822459e-01,  4.00507331e-01],\n",
            "        [-7.07608581e-01, -3.14345270e-01,  1.25113875e-03, ...,\n",
            "         -8.08430493e-01,  2.54870445e-01, -1.04938179e-01],\n",
            "        ...,\n",
            "        [ 7.04021931e-01,  1.62620455e-01,  9.78794843e-02, ...,\n",
            "         -1.18194073e-01, -2.67667845e-02,  6.76487163e-02],\n",
            "        [ 7.00935423e-01,  1.20430492e-01,  2.24221990e-01, ...,\n",
            "         -1.49878383e-01, -1.04731150e-01, -3.10150553e-02],\n",
            "        [ 4.65830624e-01,  3.63107100e-02,  1.55984193e-01, ...,\n",
            "         -1.97496489e-01, -1.08977623e-01,  4.22667786e-02]]],\n",
            "      dtype=float32)>, pooler_output=<tf.Tensor: shape=(688, 768), dtype=float32, numpy=\n",
            "array([[-0.87234765, -0.3967047 , -0.85567886, ..., -0.5996428 ,\n",
            "        -0.60494167,  0.8361169 ],\n",
            "       [-0.88086766, -0.2323565 ,  0.1594327 , ...,  0.19720143,\n",
            "        -0.5746141 ,  0.9110737 ],\n",
            "       [-0.8037872 , -0.4983936 , -0.8424049 , ..., -0.66819364,\n",
            "        -0.6176859 ,  0.70863134],\n",
            "       ...,\n",
            "       [-0.86765814, -0.4763081 , -0.8485897 , ..., -0.62210035,\n",
            "        -0.5992428 ,  0.87038606],\n",
            "       [-0.8027915 , -0.4714605 , -0.9587117 , ..., -0.8269426 ,\n",
            "        -0.62785774,  0.6685048 ],\n",
            "       [-0.7488531 , -0.46447763, -0.79031867, ..., -0.60748297,\n",
            "        -0.59233946,  0.78106546]], dtype=float32)>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**last_hidden_state**=<tf.Tensor: *shape=(688, 82, 768)* this represents each tokens' (82 = max sentence length) hidden state of each sentence (688 = total no of sentences) and the size of the hidden state = 768.\n",
        "\n",
        "**pooler_output**=<tf.Tensor: *shape=(688, 768)* this representes the ONE final encoder representation produced by BERT of hidden dimension 768.\n",
        "\n",
        "Now which one to use? last_hidden_state or pooler_output? for a task like text classification we do not need the hidden states of each word, so we can neglect the last_hidden_state"
      ],
      "metadata": {
        "id": "6xGNBqL5zgl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs.pooler_output)"
      ],
      "metadata": {
        "id": "z56Lm9CF5NuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5753e46-37fc-4e70-adb8-50f3bc7e6dd6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[-0.87234765 -0.3967047  -0.85567886 ... -0.5996428  -0.60494167\n",
            "   0.8361169 ]\n",
            " [-0.88086766 -0.2323565   0.1594327  ...  0.19720143 -0.5746141\n",
            "   0.9110737 ]\n",
            " [-0.8037872  -0.4983936  -0.8424049  ... -0.66819364 -0.6176859\n",
            "   0.70863134]\n",
            " ...\n",
            " [-0.86765814 -0.4763081  -0.8485897  ... -0.62210035 -0.5992428\n",
            "   0.87038606]\n",
            " [-0.8027915  -0.4714605  -0.9587117  ... -0.8269426  -0.62785774\n",
            "   0.6685048 ]\n",
            " [-0.7488531  -0.46447763 -0.79031867 ... -0.60748297 -0.59233946\n",
            "   0.78106546]], shape=(688, 768), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "array_size = (688, 21)\n",
        "labels_array = np.zeros(array_size)\n",
        "print(labels_array)\n",
        "i = 0\n",
        "for label in cleaned_labels:\n",
        "  for sub_label in label:\n",
        "    for number in sub_label:\n",
        "      labels_array[i][number] = 1\n",
        "  i += 1\n",
        "\n",
        "print(labels_array)\n",
        "label_tensor = tf.convert_to_tensor(labels_array)\n",
        "\n",
        "print(label_tensor.shape)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6vhQORkW2ohh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93346a1c-9dc2-455b-c5b5-f2559e5534e6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]]\n",
            "(688, 21)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the FFN using the BERT encodings and labels\n"
      ],
      "metadata": {
        "id": "abTKr8icuO5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_UNITS = 512\n",
        "NUM_UNITS2 = 128\n",
        "NUM_CLASSES = 21\n",
        "\n",
        "ffn = keras.Sequential([\n",
        "  layers.Dense(NUM_UNITS, activation='relu'),\n",
        "  layers.Dense(NUM_UNITS2, activation='relu'),\n",
        "  layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "UNU6FuKouVl5"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ffn.compile(optimizer='adam',\n",
        "            loss='binary_crossentropy',\n",
        "            metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "DYMw3V7dvZ1F"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs['pooler_output'].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPgYRmCIxAoL",
        "outputId": "7513bd4f-c0b2-4196-93eb-b92b519dd3d8"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(688, 768)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS =  500\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "\n",
        "train_loop = ffn.fit(outputs['pooler_output'] ,label_tensor, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvrq3X1wvgTr",
        "outputId": "3e672f27-cf90-4667-8bfa-f73e0dc04f1a"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0017 - accuracy: 0.7616\n",
            "Epoch 2/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.7907\n",
            "Epoch 3/500\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 0.7515\n",
            "Epoch 4/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0015 - accuracy: 0.7820\n",
            "Epoch 5/500\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 0.7631\n",
            "Epoch 6/500\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 0.7544\n",
            "Epoch 7/500\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.7733\n",
            "Epoch 8/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.7878\n",
            "Epoch 9/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.7689\n",
            "Epoch 10/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.7660\n",
            "Epoch 11/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.7689\n",
            "Epoch 12/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.7878\n",
            "Epoch 13/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.7471\n",
            "Epoch 14/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.7471\n",
            "Epoch 15/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0019 - accuracy: 0.7791\n",
            "Epoch 16/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.7892\n",
            "Epoch 17/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0030 - accuracy: 0.7747\n",
            "Epoch 18/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0027 - accuracy: 0.7660\n",
            "Epoch 19/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0023 - accuracy: 0.7703\n",
            "Epoch 20/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 0.7791\n",
            "Epoch 21/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 0.7544\n",
            "Epoch 22/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 0.7485\n",
            "Epoch 23/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0019 - accuracy: 0.7660\n",
            "Epoch 24/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0024 - accuracy: 0.7776\n",
            "Epoch 25/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 0.7718\n",
            "Epoch 26/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.7587\n",
            "Epoch 27/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0023 - accuracy: 0.7311\n",
            "Epoch 28/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 0.7703\n",
            "Epoch 29/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0024 - accuracy: 0.7718\n",
            "Epoch 30/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 0.7762\n",
            "Epoch 31/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0019 - accuracy: 0.7863\n",
            "Epoch 32/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.7689\n",
            "Epoch 33/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.7456\n",
            "Epoch 34/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.7733\n",
            "Epoch 35/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 0.7747\n",
            "Epoch 36/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.7733\n",
            "Epoch 37/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0015 - accuracy: 0.7907\n",
            "Epoch 38/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0016 - accuracy: 0.7544\n",
            "Epoch 39/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.7936\n",
            "Epoch 40/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.7718\n",
            "Epoch 41/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.7529\n",
            "Epoch 42/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.7733\n",
            "Epoch 43/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.7500\n",
            "Epoch 44/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.8052\n",
            "Epoch 45/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 0.7733\n",
            "Epoch 46/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.7442\n",
            "Epoch 47/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.7485\n",
            "Epoch 48/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0019 - accuracy: 0.7951\n",
            "Epoch 49/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 0.7849\n",
            "Epoch 50/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.7311\n",
            "Epoch 51/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0020 - accuracy: 0.8067\n",
            "Epoch 52/500\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0028 - accuracy: 0.7805\n",
            "Epoch 53/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 0.7791\n",
            "Epoch 54/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0021 - accuracy: 0.7355\n",
            "Epoch 55/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.7747\n",
            "Epoch 56/500\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0020 - accuracy: 0.7718\n",
            "Epoch 57/500\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 0.7573\n",
            "Epoch 58/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.7907\n",
            "Epoch 59/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 0.7776\n",
            "Epoch 60/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0020 - accuracy: 0.7573\n",
            "Epoch 61/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0027 - accuracy: 0.7645\n",
            "Epoch 62/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0023 - accuracy: 0.7529\n",
            "Epoch 63/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.7544\n",
            "Epoch 64/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0045 - accuracy: 0.7326\n",
            "Epoch 65/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0100 - accuracy: 0.7820\n",
            "Epoch 66/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0190 - accuracy: 0.6977\n",
            "Epoch 67/500\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.0583 - accuracy: 0.6686\n",
            "Epoch 68/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.1075 - accuracy: 0.6642\n",
            "Epoch 69/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0431 - accuracy: 0.7180\n",
            "Epoch 70/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0231 - accuracy: 0.7398\n",
            "Epoch 71/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0185 - accuracy: 0.7515\n",
            "Epoch 72/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0134 - accuracy: 0.7151\n",
            "Epoch 73/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0104 - accuracy: 0.7573\n",
            "Epoch 74/500\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0066 - accuracy: 0.7602\n",
            "Epoch 75/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0057 - accuracy: 0.7791\n",
            "Epoch 76/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0071 - accuracy: 0.7631\n",
            "Epoch 77/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0081 - accuracy: 0.7515\n",
            "Epoch 78/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0344 - accuracy: 0.7238\n",
            "Epoch 79/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0223 - accuracy: 0.7587\n",
            "Epoch 80/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0140 - accuracy: 0.7616\n",
            "Epoch 81/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0073 - accuracy: 0.7820\n",
            "Epoch 82/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0052 - accuracy: 0.7485\n",
            "Epoch 83/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0042 - accuracy: 0.7282\n",
            "Epoch 84/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0038 - accuracy: 0.7965\n",
            "Epoch 85/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0029 - accuracy: 0.7631\n",
            "Epoch 86/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0022 - accuracy: 0.7878\n",
            "Epoch 87/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.7573\n",
            "Epoch 88/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0019 - accuracy: 0.7762\n",
            "Epoch 89/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0017 - accuracy: 0.7660\n",
            "Epoch 90/500\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.7820\n",
            "Epoch 91/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 0.7674\n",
            "Epoch 92/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.7573\n",
            "Epoch 93/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.7878\n",
            "Epoch 94/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 0.7645\n",
            "Epoch 95/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 0.7602\n",
            "Epoch 96/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.7834\n",
            "Epoch 97/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0013 - accuracy: 0.7689\n",
            "Epoch 98/500\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 0.7529\n",
            "Epoch 99/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.7849\n",
            "Epoch 100/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.7573\n",
            "Epoch 101/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0015 - accuracy: 0.7776\n",
            "Epoch 102/500\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0014 - accuracy: 0.7849\n",
            "Epoch 103/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.7733\n",
            "Epoch 104/500\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 0.7602\n",
            "Epoch 105/500\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0014 - accuracy: 0.7703\n",
            "Epoch 106/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 0.7471\n",
            "Epoch 107/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0014 - accuracy: 0.7878\n",
            "Epoch 108/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 0.7776\n",
            "Epoch 109/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.7573\n",
            "Epoch 110/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0015 - accuracy: 0.7805\n",
            "Epoch 111/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.7616\n",
            "Epoch 112/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.7326\n",
            "Epoch 113/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 0.7922\n",
            "Epoch 114/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.7922\n",
            "Epoch 115/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 0.7660\n",
            "Epoch 116/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 0.7602\n",
            "Epoch 117/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 0.7500\n",
            "Epoch 118/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.7544\n",
            "Epoch 119/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0012 - accuracy: 0.7660\n",
            "Epoch 120/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0015 - accuracy: 0.7951\n",
            "Epoch 121/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.7791\n",
            "Epoch 122/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 0.7398\n",
            "Epoch 123/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 0.7820\n",
            "Epoch 124/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 0.7544\n",
            "Epoch 125/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 0.7805\n",
            "Epoch 126/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 0.7747\n",
            "Epoch 127/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 0.7573\n",
            "Epoch 128/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 0.7427\n",
            "Epoch 129/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 0.7907\n",
            "Epoch 130/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 0.7311\n",
            "Epoch 131/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.8009\n",
            "Epoch 132/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 0.7471\n",
            "Epoch 133/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 0.7820\n",
            "Epoch 134/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 0.7558\n",
            "Epoch 135/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 0.7922\n",
            "Epoch 136/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 0.7166\n",
            "Epoch 137/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0023 - accuracy: 0.8067\n",
            "Epoch 138/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 0.7355\n",
            "Epoch 139/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.7936\n",
            "Epoch 140/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 0.7427\n",
            "Epoch 141/500\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0019 - accuracy: 0.7544\n",
            "Epoch 142/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0015 - accuracy: 0.7863\n",
            "Epoch 143/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 0.7689\n",
            "Epoch 144/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 0.7689\n",
            "Epoch 145/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 0.7369\n",
            "Epoch 146/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 0.7922\n",
            "Epoch 147/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 0.7631\n",
            "Epoch 148/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 0.7456\n",
            "Epoch 149/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0012 - accuracy: 0.7951\n",
            "Epoch 150/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 0.7529\n",
            "Epoch 151/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 0.7892\n",
            "Epoch 152/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 0.7587\n",
            "Epoch 153/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 0.7733\n",
            "Epoch 154/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 0.7762\n",
            "Epoch 155/500\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0011 - accuracy: 0.7384\n",
            "Epoch 156/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0019 - accuracy: 0.7587\n",
            "Epoch 157/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 0.7515\n",
            "Epoch 158/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 0.7703\n",
            "Epoch 159/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0020 - accuracy: 0.7500\n",
            "Epoch 160/500\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0013 - accuracy: 0.8067\n",
            "Epoch 161/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0015 - accuracy: 0.7456\n",
            "Epoch 162/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 0.7674\n",
            "Epoch 163/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0010 - accuracy: 0.7936\n",
            "Epoch 164/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 0.7616\n",
            "Epoch 165/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 0.8110\n",
            "Epoch 166/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 0.7558\n",
            "Epoch 167/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0015 - accuracy: 0.7645\n",
            "Epoch 168/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 0.7471\n",
            "Epoch 169/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 0.7834\n",
            "Epoch 170/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0017 - accuracy: 0.7805\n",
            "Epoch 171/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0012 - accuracy: 0.7529\n",
            "Epoch 172/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 0.7820\n",
            "Epoch 173/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 0.7282\n",
            "Epoch 174/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 0.7791\n",
            "Epoch 175/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 0.7544\n",
            "Epoch 176/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 0.7733\n",
            "Epoch 177/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0011 - accuracy: 0.7762\n",
            "Epoch 178/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 0.7544\n",
            "Epoch 179/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0011 - accuracy: 0.7834\n",
            "Epoch 180/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0013 - accuracy: 0.7529\n",
            "Epoch 181/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 0.7224\n",
            "Epoch 182/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.8125\n",
            "Epoch 183/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 0.7064\n",
            "Epoch 184/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 0.7733\n",
            "Epoch 185/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0015 - accuracy: 0.7762\n",
            "Epoch 186/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0016 - accuracy: 0.7384\n",
            "Epoch 187/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.7980\n",
            "Epoch 188/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0017 - accuracy: 0.7747\n",
            "Epoch 189/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 0.7660\n",
            "Epoch 190/500\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0012 - accuracy: 0.7718\n",
            "Epoch 191/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 0.7602\n",
            "Epoch 192/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 0.7703\n",
            "Epoch 193/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 0.8038\n",
            "Epoch 194/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 0.7442\n",
            "Epoch 195/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 0.8241\n",
            "Epoch 196/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 0.7326\n",
            "Epoch 197/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 0.7602\n",
            "Epoch 198/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0021 - accuracy: 0.7326\n",
            "Epoch 199/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.7616\n",
            "Epoch 200/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0015 - accuracy: 0.7820\n",
            "Epoch 201/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0016 - accuracy: 0.7616\n",
            "Epoch 202/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 0.7951\n",
            "Epoch 203/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 0.7485\n",
            "Epoch 204/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 0.7703\n",
            "Epoch 205/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 0.8009\n",
            "Epoch 206/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 0.7500\n",
            "Epoch 207/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 0.7674\n",
            "Epoch 208/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 0.7980\n",
            "Epoch 209/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 0.7122\n",
            "Epoch 210/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0017 - accuracy: 0.7892\n",
            "Epoch 211/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0018 - accuracy: 0.7689\n",
            "Epoch 212/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0015 - accuracy: 0.7631\n",
            "Epoch 213/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.7573\n",
            "Epoch 214/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 0.7805\n",
            "Epoch 215/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 0.7616\n",
            "Epoch 216/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 0.7442\n",
            "Epoch 217/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0010 - accuracy: 0.7776\n",
            "Epoch 218/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 9.9427e-04 - accuracy: 0.7965\n",
            "Epoch 219/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0012 - accuracy: 0.7703\n",
            "Epoch 220/500\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.9575e-04 - accuracy: 0.7500\n",
            "Epoch 221/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 0.8023\n",
            "Epoch 222/500\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0013 - accuracy: 0.7238\n",
            "Epoch 223/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 0.7936\n",
            "Epoch 224/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0011 - accuracy: 0.7500\n",
            "Epoch 225/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0013 - accuracy: 0.7645\n",
            "Epoch 226/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0010 - accuracy: 0.7907\n",
            "Epoch 227/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0012 - accuracy: 0.7485\n",
            "Epoch 228/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0010 - accuracy: 0.7689\n",
            "Epoch 229/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 9.6271e-04 - accuracy: 0.7544\n",
            "Epoch 230/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 0.8038\n",
            "Epoch 231/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0016 - accuracy: 0.7340\n",
            "Epoch 232/500\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0021 - accuracy: 0.7398\n",
            "Epoch 233/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 0.7500\n",
            "Epoch 234/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0012 - accuracy: 0.8023\n",
            "Epoch 235/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0015 - accuracy: 0.7485\n",
            "Epoch 236/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 0.7471\n",
            "Epoch 237/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 0.7863\n",
            "Epoch 238/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0011 - accuracy: 0.7544\n",
            "Epoch 239/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0017 - accuracy: 0.7922\n",
            "Epoch 240/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0016 - accuracy: 0.7907\n",
            "Epoch 241/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 0.7413\n",
            "Epoch 242/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 0.7544\n",
            "Epoch 243/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0013 - accuracy: 0.7994\n",
            "Epoch 244/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0019 - accuracy: 0.7398\n",
            "Epoch 245/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0015 - accuracy: 0.7398\n",
            "Epoch 246/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 0.7994\n",
            "Epoch 247/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0015 - accuracy: 0.7602\n",
            "Epoch 248/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 0.7398\n",
            "Epoch 249/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 0.8125\n",
            "Epoch 250/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0022 - accuracy: 0.7456\n",
            "Epoch 251/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0017 - accuracy: 0.8125\n",
            "Epoch 252/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 0.7180\n",
            "Epoch 253/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0016 - accuracy: 0.7980\n",
            "Epoch 254/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0016 - accuracy: 0.7718\n",
            "Epoch 255/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 0.7645\n",
            "Epoch 256/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 0.7442\n",
            "Epoch 257/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 0.7602\n",
            "Epoch 258/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0012 - accuracy: 0.8023\n",
            "Epoch 259/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 0.7427\n",
            "Epoch 260/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 9.0689e-04 - accuracy: 0.7500\n",
            "Epoch 261/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 0.7326\n",
            "Epoch 262/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 0.8023\n",
            "Epoch 263/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 0.7544\n",
            "Epoch 264/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0012 - accuracy: 0.7674\n",
            "Epoch 265/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0017 - accuracy: 0.7369\n",
            "Epoch 266/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0016 - accuracy: 0.7442\n",
            "Epoch 267/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 0.7413\n",
            "Epoch 268/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0013 - accuracy: 0.7762\n",
            "Epoch 269/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0011 - accuracy: 0.7587\n",
            "Epoch 270/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 9.6649e-04 - accuracy: 0.7922\n",
            "Epoch 271/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 0.7122\n",
            "Epoch 272/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0014 - accuracy: 0.7907\n",
            "Epoch 273/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 0.7703\n",
            "Epoch 274/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 0.7791\n",
            "Epoch 275/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 0.7587\n",
            "Epoch 276/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0014 - accuracy: 0.7602\n",
            "Epoch 277/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0017 - accuracy: 0.7645\n",
            "Epoch 278/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0017 - accuracy: 0.7892\n",
            "Epoch 279/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0024 - accuracy: 0.7733\n",
            "Epoch 280/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 0.7398\n",
            "Epoch 281/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 0.7558\n",
            "Epoch 282/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 0.7587\n",
            "Epoch 283/500\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0013 - accuracy: 0.7951\n",
            "Epoch 284/500\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0021 - accuracy: 0.7878\n",
            "Epoch 285/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 0.7427\n",
            "Epoch 286/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0017 - accuracy: 0.8140\n",
            "Epoch 287/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0019 - accuracy: 0.7805\n",
            "Epoch 288/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0011 - accuracy: 0.7442\n",
            "Epoch 289/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0012 - accuracy: 0.7427\n",
            "Epoch 290/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 0.7951\n",
            "Epoch 291/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0014 - accuracy: 0.7238\n",
            "Epoch 292/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 0.7689\n",
            "Epoch 293/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0027 - accuracy: 0.7907\n",
            "Epoch 294/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0018 - accuracy: 0.7587\n",
            "Epoch 295/500\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0025 - accuracy: 0.7834\n",
            "Epoch 296/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 0.7733\n",
            "Epoch 297/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0027 - accuracy: 0.7791\n",
            "Epoch 298/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0015 - accuracy: 0.7311\n",
            "Epoch 299/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 0.7878\n",
            "Epoch 300/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0019 - accuracy: 0.7297\n",
            "Epoch 301/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0012 - accuracy: 0.7747\n",
            "Epoch 302/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 0.7529\n",
            "Epoch 303/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0021 - accuracy: 0.7892\n",
            "Epoch 304/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0016 - accuracy: 0.7485\n",
            "Epoch 305/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0018 - accuracy: 0.7776\n",
            "Epoch 306/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0021 - accuracy: 0.7384\n",
            "Epoch 307/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0017 - accuracy: 0.8081\n",
            "Epoch 308/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0012 - accuracy: 0.7500\n",
            "Epoch 309/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 0.8038\n",
            "Epoch 310/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0011 - accuracy: 0.7297\n",
            "Epoch 311/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0014 - accuracy: 0.7965\n",
            "Epoch 312/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 0.7849\n",
            "Epoch 313/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0015 - accuracy: 0.7805\n",
            "Epoch 314/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.7936\n",
            "Epoch 315/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0016 - accuracy: 0.7267\n",
            "Epoch 316/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0023 - accuracy: 0.7994\n",
            "Epoch 317/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0019 - accuracy: 0.7544\n",
            "Epoch 318/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0020 - accuracy: 0.7733\n",
            "Epoch 319/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.7805\n",
            "Epoch 320/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0012 - accuracy: 0.7515\n",
            "Epoch 321/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 0.7529\n",
            "Epoch 322/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 0.7820\n",
            "Epoch 323/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0012 - accuracy: 0.7238\n",
            "Epoch 324/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.7907\n",
            "Epoch 325/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0015 - accuracy: 0.7515\n",
            "Epoch 326/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0021 - accuracy: 0.7834\n",
            "Epoch 327/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0019 - accuracy: 0.7602\n",
            "Epoch 328/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.7515\n",
            "Epoch 329/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 0.7703\n",
            "Epoch 330/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 9.8378e-04 - accuracy: 0.7791\n",
            "Epoch 331/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0013 - accuracy: 0.7282\n",
            "Epoch 332/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0011 - accuracy: 0.8052\n",
            "Epoch 333/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 0.7529\n",
            "Epoch 334/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 9.7898e-04 - accuracy: 0.7573\n",
            "Epoch 335/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 9.1842e-04 - accuracy: 0.7500\n",
            "Epoch 336/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0013 - accuracy: 0.7776\n",
            "Epoch 337/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0010 - accuracy: 0.7791\n",
            "Epoch 338/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 9.3166e-04 - accuracy: 0.7660\n",
            "Epoch 339/500\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 9.6171e-04 - accuracy: 0.7602\n",
            "Epoch 340/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 9.2871e-04 - accuracy: 0.7849\n",
            "Epoch 341/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 9.2641e-04 - accuracy: 0.7660\n",
            "Epoch 342/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 9.6585e-04 - accuracy: 0.7994\n",
            "Epoch 343/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 8.8472e-04 - accuracy: 0.7485\n",
            "Epoch 344/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 9.1189e-04 - accuracy: 0.7689\n",
            "Epoch 345/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 0.7892\n",
            "Epoch 346/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 0.7573\n",
            "Epoch 347/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 9.4037e-04 - accuracy: 0.7427\n",
            "Epoch 348/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0019 - accuracy: 0.7907\n",
            "Epoch 349/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 0.7733\n",
            "Epoch 350/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0018 - accuracy: 0.7602\n",
            "Epoch 351/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 0.7616\n",
            "Epoch 352/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 0.7820\n",
            "Epoch 353/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 0.7834\n",
            "Epoch 354/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0033 - accuracy: 0.7384\n",
            "Epoch 355/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0107 - accuracy: 0.7369\n",
            "Epoch 356/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1149 - accuracy: 0.6613\n",
            "Epoch 357/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2390 - accuracy: 0.5698\n",
            "Epoch 358/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1459 - accuracy: 0.6352\n",
            "Epoch 359/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0881 - accuracy: 0.7253\n",
            "Epoch 360/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0604 - accuracy: 0.7020\n",
            "Epoch 361/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0388 - accuracy: 0.7442\n",
            "Epoch 362/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0242 - accuracy: 0.7282\n",
            "Epoch 363/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0161 - accuracy: 0.7791\n",
            "Epoch 364/500\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0130 - accuracy: 0.7398\n",
            "Epoch 365/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0090 - accuracy: 0.7689\n",
            "Epoch 366/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0092 - accuracy: 0.8125\n",
            "Epoch 367/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0077 - accuracy: 0.7616\n",
            "Epoch 368/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0060 - accuracy: 0.7442\n",
            "Epoch 369/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0053 - accuracy: 0.7805\n",
            "Epoch 370/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0043 - accuracy: 0.7544\n",
            "Epoch 371/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0037 - accuracy: 0.7951\n",
            "Epoch 372/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0032 - accuracy: 0.7820\n",
            "Epoch 373/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0029 - accuracy: 0.7703\n",
            "Epoch 374/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0030 - accuracy: 0.7820\n",
            "Epoch 375/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 0.7689\n",
            "Epoch 376/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0026 - accuracy: 0.7936\n",
            "Epoch 377/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0025 - accuracy: 0.7849\n",
            "Epoch 378/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0024 - accuracy: 0.7922\n",
            "Epoch 379/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0023 - accuracy: 0.7762\n",
            "Epoch 380/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 0.7980\n",
            "Epoch 381/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0025 - accuracy: 0.7587\n",
            "Epoch 382/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0025 - accuracy: 0.8140\n",
            "Epoch 383/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0024 - accuracy: 0.7471\n",
            "Epoch 384/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0026 - accuracy: 0.8052\n",
            "Epoch 385/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0025 - accuracy: 0.7529\n",
            "Epoch 386/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0022 - accuracy: 0.7878\n",
            "Epoch 387/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0022 - accuracy: 0.7951\n",
            "Epoch 388/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0024 - accuracy: 0.7515\n",
            "Epoch 389/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0024 - accuracy: 0.7936\n",
            "Epoch 390/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0023 - accuracy: 0.7515\n",
            "Epoch 391/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 0.7965\n",
            "Epoch 392/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 0.7820\n",
            "Epoch 393/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0020 - accuracy: 0.7733\n",
            "Epoch 394/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0019 - accuracy: 0.7892\n",
            "Epoch 395/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0019 - accuracy: 0.7529\n",
            "Epoch 396/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 0.8052\n",
            "Epoch 397/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 0.7674\n",
            "Epoch 398/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 0.7936\n",
            "Epoch 399/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.7631\n",
            "Epoch 400/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0018 - accuracy: 0.8038\n",
            "Epoch 401/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 0.7529\n",
            "Epoch 402/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0019 - accuracy: 0.8096\n",
            "Epoch 403/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.7602\n",
            "Epoch 404/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.7820\n",
            "Epoch 405/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.7660\n",
            "Epoch 406/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.7674\n",
            "Epoch 407/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.7805\n",
            "Epoch 408/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0017 - accuracy: 0.7892\n",
            "Epoch 409/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0018 - accuracy: 0.7834\n",
            "Epoch 410/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 0.7733\n",
            "Epoch 411/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.7791\n",
            "Epoch 412/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0016 - accuracy: 0.7791\n",
            "Epoch 413/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0016 - accuracy: 0.7878\n",
            "Epoch 414/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.7674\n",
            "Epoch 415/500\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.7645\n",
            "Epoch 416/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.7922\n",
            "Epoch 417/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.7645\n",
            "Epoch 418/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.7805\n",
            "Epoch 419/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.7544\n",
            "Epoch 420/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0016 - accuracy: 0.8038\n",
            "Epoch 421/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.7660\n",
            "Epoch 422/500\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 0.7965\n",
            "Epoch 423/500\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 0.7471\n",
            "Epoch 424/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0019 - accuracy: 0.7776\n",
            "Epoch 425/500\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0016 - accuracy: 0.7674\n",
            "Epoch 426/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.7849\n",
            "Epoch 427/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.7805\n",
            "Epoch 428/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.7892\n",
            "Epoch 429/500\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 0.7674\n",
            "Epoch 430/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 0.7791\n",
            "Epoch 431/500\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0015 - accuracy: 0.7733\n",
            "Epoch 432/500\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0015 - accuracy: 0.7980\n",
            "Epoch 433/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.7689\n",
            "Epoch 434/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.7994\n",
            "Epoch 435/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.7587\n",
            "Epoch 436/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.7994\n",
            "Epoch 437/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.7558\n",
            "Epoch 438/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.7980\n",
            "Epoch 439/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 0.7645\n",
            "Epoch 440/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.7922\n",
            "Epoch 441/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.7369\n",
            "Epoch 442/500\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.8183\n",
            "Epoch 443/500\n",
            "6/6 [==============================] - 0s 6ms/step - loss: 0.0017 - accuracy: 0.7485\n",
            "Epoch 444/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.8140\n",
            "Epoch 445/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0016 - accuracy: 0.7369\n",
            "Epoch 446/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0015 - accuracy: 0.8154\n",
            "Epoch 447/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.7718\n",
            "Epoch 448/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0015 - accuracy: 0.7660\n",
            "Epoch 449/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 0.7907\n",
            "Epoch 450/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 0.7805\n",
            "Epoch 451/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0012 - accuracy: 0.7733\n",
            "Epoch 452/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0013 - accuracy: 0.7907\n",
            "Epoch 453/500\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0014 - accuracy: 0.7544\n",
            "Epoch 454/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0014 - accuracy: 0.8081\n",
            "Epoch 455/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0018 - accuracy: 0.7849\n",
            "Epoch 456/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 0.7384\n",
            "Epoch 457/500\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0019 - accuracy: 0.7994\n",
            "Epoch 458/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0018 - accuracy: 0.7471\n",
            "Epoch 459/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0016 - accuracy: 0.8096\n",
            "Epoch 460/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0016 - accuracy: 0.7369\n",
            "Epoch 461/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0016 - accuracy: 0.8227\n",
            "Epoch 462/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0020 - accuracy: 0.7209\n",
            "Epoch 463/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 0.7922\n",
            "Epoch 464/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 0.7674\n",
            "Epoch 465/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0015 - accuracy: 0.8154\n",
            "Epoch 466/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0015 - accuracy: 0.7311\n",
            "Epoch 467/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0015 - accuracy: 0.8125\n",
            "Epoch 468/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0017 - accuracy: 0.7529\n",
            "Epoch 469/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 0.7965\n",
            "Epoch 470/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0013 - accuracy: 0.7762\n",
            "Epoch 471/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 0.7776\n",
            "Epoch 472/500\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0014 - accuracy: 0.8009\n",
            "Epoch 473/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 0.7616\n",
            "Epoch 474/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0014 - accuracy: 0.7456\n",
            "Epoch 475/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0014 - accuracy: 0.8212\n",
            "Epoch 476/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0016 - accuracy: 0.7645\n",
            "Epoch 477/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0013 - accuracy: 0.7660\n",
            "Epoch 478/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 0.7907\n",
            "Epoch 479/500\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 0.7733\n",
            "Epoch 480/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 0.7805\n",
            "Epoch 481/500\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0012 - accuracy: 0.7791\n",
            "Epoch 482/500\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0013 - accuracy: 0.7776\n",
            "Epoch 483/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0012 - accuracy: 0.8038\n",
            "Epoch 484/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 0.7631\n",
            "Epoch 485/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0012 - accuracy: 0.7849\n",
            "Epoch 486/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 0.7834\n",
            "Epoch 487/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 0.7689\n",
            "Epoch 488/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 0.7994\n",
            "Epoch 489/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0011 - accuracy: 0.7558\n",
            "Epoch 490/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 0.7863\n",
            "Epoch 491/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0012 - accuracy: 0.7747\n",
            "Epoch 492/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 0.7849\n",
            "Epoch 493/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0012 - accuracy: 0.7616\n",
            "Epoch 494/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0013 - accuracy: 0.7907\n",
            "Epoch 495/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0013 - accuracy: 0.7587\n",
            "Epoch 496/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0013 - accuracy: 0.7951\n",
            "Epoch 497/500\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0014 - accuracy: 0.7340\n",
            "Epoch 498/500\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0015 - accuracy: 0.8212\n",
            "Epoch 499/500\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0022 - accuracy: 0.7253\n",
            "Epoch 500/500\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0021 - accuracy: 0.7863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model = ffn.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDHiUkoQJF5Y",
        "outputId": "394e7b57-2e02-4e19-f514-259851e06f2b"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 512)               393728    \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 128)               65664     \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 21)                2709      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 462,101\n",
            "Trainable params: 462,101\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3340db535a734544b6fe1e1974d0ea9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3d218d37241457885e33760c15a3d41",
              "IPY_MODEL_79e446fd9e3644fdbacdfeaf7dab763c",
              "IPY_MODEL_3b502b16000a456c9fbafb38b0c22b47"
            ],
            "layout": "IPY_MODEL_c9eed52e69c94fa88d09fa75c70a2b45"
          }
        },
        "d3d218d37241457885e33760c15a3d41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c280541c73294c3cb9f6bafac567af97",
            "placeholder": "​",
            "style": "IPY_MODEL_2ba377279f18464d8eba9bc9dcc567d5",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "79e446fd9e3644fdbacdfeaf7dab763c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e476fbf237234c839da9e4ea98d467a3",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08e8e779ee804f7381a249c9330faeff",
            "value": 570
          }
        },
        "3b502b16000a456c9fbafb38b0c22b47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d371ef176e0043019397ea6135171c10",
            "placeholder": "​",
            "style": "IPY_MODEL_db4097ed29b84257a52c326328f410ab",
            "value": " 570/570 [00:00&lt;00:00, 10.8kB/s]"
          }
        },
        "c9eed52e69c94fa88d09fa75c70a2b45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c280541c73294c3cb9f6bafac567af97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ba377279f18464d8eba9bc9dcc567d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e476fbf237234c839da9e4ea98d467a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08e8e779ee804f7381a249c9330faeff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d371ef176e0043019397ea6135171c10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db4097ed29b84257a52c326328f410ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3221acf9214c4eee84277a0aea8ee5e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5993a4b83b54f62a5640826084e76f8",
              "IPY_MODEL_0132c2e08f6645f9b7dbd0546cc58a75",
              "IPY_MODEL_49900eb453234c46b012e5ad1600efbb"
            ],
            "layout": "IPY_MODEL_a8f26977cce74e61978a4f254b4d33a5"
          }
        },
        "c5993a4b83b54f62a5640826084e76f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fccc6c8ead264760828832a8987d0f07",
            "placeholder": "​",
            "style": "IPY_MODEL_3d88c1b8ba9e49c6a8c69a9df028a389",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "0132c2e08f6645f9b7dbd0546cc58a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4529b092309343e68781ef6e617462df",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2f83a4051794078a64af92033532fb7",
            "value": 440449768
          }
        },
        "49900eb453234c46b012e5ad1600efbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b39ac3f46afa4d3fb9df7931f30fa264",
            "placeholder": "​",
            "style": "IPY_MODEL_422bfc40a298424a83d869b7bea1342a",
            "value": " 440M/440M [00:01&lt;00:00, 324MB/s]"
          }
        },
        "a8f26977cce74e61978a4f254b4d33a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fccc6c8ead264760828832a8987d0f07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d88c1b8ba9e49c6a8c69a9df028a389": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4529b092309343e68781ef6e617462df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2f83a4051794078a64af92033532fb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b39ac3f46afa4d3fb9df7931f30fa264": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "422bfc40a298424a83d869b7bea1342a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5dc07ce609f1443dac4f9e319bb7b41a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_76d2ae9a0c12454aa52be56863213c97",
              "IPY_MODEL_a6265d2968c448689a73a68f0fd7c173",
              "IPY_MODEL_26c0be618fad4a12a692a8db6c73d857"
            ],
            "layout": "IPY_MODEL_9d7240ab80d84dfbb2a5ce1791588862"
          }
        },
        "76d2ae9a0c12454aa52be56863213c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b985d0a70a4477c9fc71f03d42f9947",
            "placeholder": "​",
            "style": "IPY_MODEL_aed466573c6248689b69868f851d36fd",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "a6265d2968c448689a73a68f0fd7c173": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ebe34fe76ac4ba8abaad54ddfd0c0db",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7bfa50c5ac954405a2a82a8fcda09799",
            "value": 28
          }
        },
        "26c0be618fad4a12a692a8db6c73d857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf58088026b54126935899029a0717c3",
            "placeholder": "​",
            "style": "IPY_MODEL_3c395f51f48d410693a9805002b6bc29",
            "value": " 28.0/28.0 [00:00&lt;00:00, 636B/s]"
          }
        },
        "9d7240ab80d84dfbb2a5ce1791588862": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b985d0a70a4477c9fc71f03d42f9947": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aed466573c6248689b69868f851d36fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ebe34fe76ac4ba8abaad54ddfd0c0db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7bfa50c5ac954405a2a82a8fcda09799": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf58088026b54126935899029a0717c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c395f51f48d410693a9805002b6bc29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "149ccabb4f884310bd4bf83c89786f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3365ec5bacca4f298f6a98513c34fc60",
              "IPY_MODEL_d31e1d71db0747749d46ad3263e6ba3e",
              "IPY_MODEL_8190f8e2646243a3aa331fa9da3f53f9"
            ],
            "layout": "IPY_MODEL_86715bab2c1d4e178550f70293b1d8dd"
          }
        },
        "3365ec5bacca4f298f6a98513c34fc60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1af1d3da999241beb6edca5d9be0e5ed",
            "placeholder": "​",
            "style": "IPY_MODEL_7427c05a56e14db1bee23faf2021a42f",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "d31e1d71db0747749d46ad3263e6ba3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e946de4597914c62a5c26905b4d427f0",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2752817ab2074c54b1080294a42851ff",
            "value": 231508
          }
        },
        "8190f8e2646243a3aa331fa9da3f53f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_192e616e76a64a4c83a2194ce99d8b72",
            "placeholder": "​",
            "style": "IPY_MODEL_95e4f960cfcb42a79459d76e505606e1",
            "value": " 232k/232k [00:00&lt;00:00, 1.44MB/s]"
          }
        },
        "86715bab2c1d4e178550f70293b1d8dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1af1d3da999241beb6edca5d9be0e5ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7427c05a56e14db1bee23faf2021a42f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e946de4597914c62a5c26905b4d427f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2752817ab2074c54b1080294a42851ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "192e616e76a64a4c83a2194ce99d8b72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95e4f960cfcb42a79459d76e505606e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1dd19af7296d4e07a12e306e2222f022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f05592e383e24b11b76d5ace879f838f",
              "IPY_MODEL_ae01135e8bc74a0ab5af2f8b7dafe87f",
              "IPY_MODEL_a3b10fb125a74d69a6195e05a63aeb72"
            ],
            "layout": "IPY_MODEL_5ffe8fbb9dbe472a87a939aff9b98a09"
          }
        },
        "f05592e383e24b11b76d5ace879f838f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9318bef1144248549d4488322471261f",
            "placeholder": "​",
            "style": "IPY_MODEL_35082f1d95984ed9b3b9bda6f6fac733",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "ae01135e8bc74a0ab5af2f8b7dafe87f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01bd41b684ce481a994f599a214abeeb",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8e184e22e344bce9dea778744be842a",
            "value": 466062
          }
        },
        "a3b10fb125a74d69a6195e05a63aeb72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ddb7c2b376748ef838460dc65f5640a",
            "placeholder": "​",
            "style": "IPY_MODEL_60a14a0c009945db8d2796a013457b37",
            "value": " 466k/466k [00:00&lt;00:00, 5.35MB/s]"
          }
        },
        "5ffe8fbb9dbe472a87a939aff9b98a09": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9318bef1144248549d4488322471261f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35082f1d95984ed9b3b9bda6f6fac733": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01bd41b684ce481a994f599a214abeeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8e184e22e344bce9dea778744be842a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ddb7c2b376748ef838460dc65f5640a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60a14a0c009945db8d2796a013457b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}